{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scripts.differentiable_pfn_evaluation import eval_model_range\n",
    "from scripts.model_builder import get_model, get_default_spec, save_model, load_model\n",
    "from scripts.transformer_prediction_interface import transformer_predict, get_params_from_config, load_model_workflow_my\n",
    "\n",
    "from scripts.model_configs import *\n",
    "\n",
    "from datasets import load_openml_list, open_cc_dids, open_cc_valid_dids\n",
    "from priors.utils import plot_prior, plot_features\n",
    "from priors.utils import uniform_int_sampler_f\n",
    "\n",
    "from scripts.tabular_metrics import calculate_score_per_method, calculate_score\n",
    "from scripts.tabular_evaluation import evaluate\n",
    "\n",
    "from priors.differentiable_prior import DifferentiableHyperparameterList, draw_random_style, merge_style_with_info\n",
    "from scripts import tabular_metrics\n",
    "from notebook_utils import *\n",
    "\n",
    "from tabpfn.priors.prior import PriorDataLoader\n",
    "from tabpfn.utils import get_uniform_single_eval_pos_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_datasets = True\n",
    "max_samples = 10000 if large_datasets else 5000\n",
    "bptt = 10000 if large_datasets else 3000\n",
    "suite='cc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "base_path = '.'\n",
    "max_features = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_models(model_string):\n",
    "    print(model_string)\n",
    "\n",
    "    for i in range(80):\n",
    "        for e in range(50):\n",
    "            exists = Path(os.path.join(base_path, f'smote+sq_models_diff_添加参数设置/prior_diff_real_checkpoint{model_string}_n_{i}_epoch_{e}.cpkt')).is_file()\n",
    "            if exists:\n",
    "                print(os.path.join(base_path, f'smote+sq_models_diff_添加参数设置/prior_diff_real_checkpoint{model_string}_n_{i}_epoch_{e}.cpkt'))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef train_function(config_sample, i, add_name=''):\\n    torch.cuda.empty_cache()\\n    start_time = time.time()\\n    N_epochs_to_save = 10\\n    \\n    \\n    # 经过本人更改的代码\\n    def save_callback(model, epoch):\\n        if not hasattr(model, 'last_saved_epoch'):\\n            model.last_saved_epoch = 0\\n        # 每1个批次保存一个模型\\n        if epoch % 1 == 0:\\n            config_sample['epoch_in_training'] = epoch\\n            save_model(model, base_path, f'my_models_diff/prior_diff_real_checkpoint{add_name}_n_{i}_epoch_{epoch}.cpkt',\\n                            config_sample)\\n            model.last_saved_epoch = model.last_saved_epoch + 1 # TODO: Rename to checkpoint\\n    \\n    model = get_model(config_sample\\n                      , device\\n                      , should_train=True\\n                      , verbose=1\\n                      , epoch_callback = save_callback)\\n    \\n    return\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def train_function(config_sample, i, add_name=''):\n",
    "    torch.cuda.empty_cache()\n",
    "    start_time = time.time()\n",
    "    N_epochs_to_save = 10\n",
    "    \n",
    "    \n",
    "    # 经过本人更改的代码\n",
    "    def save_callback(model, epoch):\n",
    "        if not hasattr(model, 'last_saved_epoch'):\n",
    "            model.last_saved_epoch = 0\n",
    "        # 每1个批次保存一个模型\n",
    "        if epoch % 1 == 0:\n",
    "            config_sample['epoch_in_training'] = epoch\n",
    "            save_model(model, base_path, f'my_models_diff/prior_diff_real_checkpoint{add_name}_n_{i}_epoch_{epoch}.cpkt',\n",
    "                            config_sample)\n",
    "            model.last_saved_epoch = model.last_saved_epoch + 1 # TODO: Rename to checkpoint\n",
    "    \n",
    "    model = get_model(config_sample\n",
    "                      , device\n",
    "                      , should_train=True\n",
    "                      , verbose=1\n",
    "                      , epoch_callback = save_callback)\n",
    "    \n",
    "    return\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_function(config_sample, i, add_name=''):\n",
    "    torch.cuda.empty_cache()\n",
    "    start_time = time.time()\n",
    "    max_saved_models = 50  # 保持最多保存 50 个模型\n",
    "    \n",
    "    # 定义保存模型的回调函数\n",
    "    def save_callback(model, epoch):\n",
    "        # 仅保存第 91 到第 130 个 epoch 的模型\n",
    "        if epoch < 91 or epoch > 130:\n",
    "            return  # 跳过第 101 到第 150 以外的 epoch，不保存模型\n",
    "        \n",
    "        if not hasattr(model, 'last_saved_epoch'):\n",
    "            model.last_saved_epoch = 0\n",
    "\n",
    "        # 保存当前模型\n",
    "        config_sample['epoch_in_training'] = epoch\n",
    "        save_path = f'smote+sq_models_diff_添加参数设置/prior_diff_real_checkpoint{add_name}_n_{i}_epoch_{epoch}.cpkt'\n",
    "        save_model(model, base_path, save_path, config_sample)\n",
    "        model.last_saved_epoch += 1  # 更新保存次数\n",
    "        \n",
    "        # 获取当前已保存的模型列表\n",
    "        saved_models = sorted(\n",
    "            [file for file in os.listdir(\"smote+sq_models_diff_添加参数设置\") if file.startswith(f\"prior_diff_real_checkpoint{add_name}_n_{i}_\")],\n",
    "            key=lambda x: int(x.split('_epoch_')[-1].split('.cpkt')[0])  # 按 epoch 排序\n",
    "        )\n",
    "        \n",
    "        # 保持最多保存 50 个模型，删除最早的模型\n",
    "        if len(saved_models) > max_saved_models:\n",
    "            oldest_model = saved_models[0]\n",
    "            os.remove(os.path.join(\"smote+sq_models_diff_添加参数设置\", oldest_model))  # 删除最早的模型文件\n",
    "            \n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "    # 初始化并训练模型\n",
    "    model = get_model(config_sample, device, should_train=True, verbose=1, epoch_callback=save_callback)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define prior settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def reload_config(config_type='causal', task_type='multiclass', longer=0, use_sequential_attention=False):\n",
    "    config = get_prior_config(config_type=config_type)\n",
    "    \n",
    "    config['prior_type'], config['differentiable'], config['flexible'] = 'prior_bag', True, True\n",
    "    \n",
    "    model_string = ''\n",
    "    \n",
    "    config['epochs'] = 12000\n",
    "    config['recompute_attn'] = True\n",
    "\n",
    "    config['max_num_classes'] = 2\n",
    "    config['num_classes'] = uniform_int_sampler_f(2, config['max_num_classes'])\n",
    "    config['balanced'] = False\n",
    "    model_string = model_string + '_multiclass'\n",
    "    \n",
    "    model_string = model_string + '_'+datetime.now().strftime(\"%m_%d_%Y_%H_%M_%S\")\n",
    "    \n",
    "    # 新增顺序注意力参数\n",
    "    config['use_sequential_attention'] = use_sequential_attention\n",
    "    \n",
    "    return config, model_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualize Prior samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config, model_string = reload_config(longer=1, use_sequential_attention=True)\n",
    "\n",
    "config['bptt_extra_samples'] = None\n",
    "\n",
    "# diff\n",
    "config['output_multiclass_ordered_p'] = 0.\n",
    "del config['differentiable_hyperparameters']['output_multiclass_ordered_p']\n",
    "\n",
    "config['multiclass_type'] = 'rank'\n",
    "del config['differentiable_hyperparameters']['multiclass_type']\n",
    "\n",
    "config['sampling'] = 'normal' # vielleicht schlecht?\n",
    "del config['differentiable_hyperparameters']['sampling']\n",
    "\n",
    "config['pre_sample_causes'] = True\n",
    "# end diff\n",
    "\n",
    "config['multiclass_loss_type'] = 'nono' # 'compatible'\n",
    "config['normalize_to_ranking'] = False # False\n",
    "\n",
    "config['categorical_feature_p'] = .2 # diff: .0\n",
    "\n",
    "# turn this back on in a random search!?\n",
    "config['nan_prob_no_reason'] = .0\n",
    "config['nan_prob_unknown_reason'] = .0 # diff: .0\n",
    "config['set_value_to_nan'] = .1 # diff: 1.\n",
    "\n",
    "config['normalize_with_sqrt'] = False\n",
    "\n",
    "config['new_mlp_per_example'] = True\n",
    "config['prior_mlp_scale_weights_sqrt'] = True\n",
    "config['batch_size_per_gp_sample'] = None\n",
    "\n",
    "config['normalize_ignore_label_too'] = False\n",
    "\n",
    "config['differentiable_hps_as_style'] = False\n",
    "config['max_eval_pos'] = 1000\n",
    "\n",
    "config['random_feature_rotation'] = True\n",
    "config['rotate_normalized_labels'] = True\n",
    "\n",
    "config[\"mix_activations\"] = False # False heisst eig True\n",
    "\n",
    "config['emsize'] = 512\n",
    "config['nhead'] = config['emsize'] // 128\n",
    "config['bptt'] = 1024+128\n",
    "config['canonical_y_encoder'] = False\n",
    "\n",
    "    \n",
    "config['aggregate_k_gradients'] = 8\n",
    "config['batch_size'] = 16*config['aggregate_k_gradients']\n",
    "config['num_steps'] = 1024//config['aggregate_k_gradients']\n",
    "config['epochs'] = 130\n",
    "config['total_available_time_in_s'] = None #60*60*22 # 22 hours for some safety...\n",
    "\n",
    "config['train_mixed_precision'] = True\n",
    "config['efficient_eval_masking'] = True\n",
    "\n",
    "config_sample = evaluate_hypers(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "epoch:130\n",
      "steps_per_epoch:1024\n",
      "batch_size:16\n",
      "aggregate_k_gradients:8\n",
      "梯度下降的batch_size:128\n",
      "num_datasets:2129920\n",
      "train_mixed_precision:True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.81 M parameters\n",
      "get_batch is being called\n",
      "get_batch is being called\n",
      "get_batch is being called\n",
      "get_batch is being called\n",
      "get_batch is being called\n",
      "get_batch is being called\n",
      "get_batch is being called\n",
      "get_batch is being called\n",
      "get_batch is being called\n",
      "get_batch is being called\n",
      "get_batch is being called\n",
      "get_batch is being called\n",
      "get_batch is being called\n",
      "get_batch is being called\n",
      "get_batch is being called\n",
      "get_batch is being called\n",
      "get_batch is being called\n",
      "get_batch is being called\n",
      "get_batch is being called\n",
      "get_batch is being called\n",
      "get_batch is being called\n",
      "get_batch is being called\n",
      "get_batch is being called\n",
      "get_batch is being called\n",
      "get_batch is being called\n",
      "get_batch is being called\n",
      "get_batch is being called\n",
      "get_batch is being called\n",
      "get_batch is being called\n",
      "get_batch is being called\n",
      "get_batch is being called\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[267, 16]' is invalid for input of size 4005",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 37\u001b[0m, in \u001b[0;36mtrain_function\u001b[0;34m(config_sample, i, add_name)\u001b[0m\n\u001b[1;32m     30\u001b[0m         os\u001b[38;5;241m.\u001b[39mremove(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmote+sq_models_diff_添加参数设置\u001b[39m\u001b[38;5;124m\"\u001b[39m, oldest_model))  \u001b[38;5;66;03m# 删除最早的模型文件\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# 初始化并训练模型\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshould_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_callback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/autodl-fs/data/Sq-TabPFN/tabpfn/scripts/model_builder.py:289\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(config, device, should_train, verbose, state_dict, epoch_callback)\u001b[0m\n\u001b[1;32m    286\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_train \u001b[38;5;28;01melse\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m#print('MODEL BUILDER', model_proto, extra_kwargs['get_batch'])\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_proto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataLoader\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle_encoder_generator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mencoders\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStyleEncoder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muse_style\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    293\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43memsize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnhead\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnhead\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# For unsupervised learning change to NanHandlingEncoder\u001b[39;49;00m\n\u001b[1;32m    296\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_encoder_generator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mencoders\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_Canonical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_num_classes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcanonical_y_encoder\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mencoders\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_encoder_generator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    298\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnlayers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnlayers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnhid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43memsize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnhid_factor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\n\u001b[1;32m    303\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbptt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbptt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdropout\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_steps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msingle_eval_pos_gen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_uniform_single_eval_pos_sampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_eval_pos\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbptt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin_eval_pos\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_weights_from_this_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maggregate_k_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maggregate_k_gradients\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecompute_attn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecompute_attn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch_callback\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbptt_extra_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbptt_extra_samples\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_mixed_precision\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_mixed_precision\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_prior_kwargs_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_features\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_features\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhyperparameters\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprior_hyperparameters\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#, 'dynamic_batch_size': 1 if ('num_global_att_tokens' in config and config['num_global_att_tokens']) else 2\u001b[39;49;00m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size_per_gp_sample\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size_per_gp_sample\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kwargs\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m              \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tabpfn/train.py:251\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(priordataloader_class, criterion, encoder_generator, emsize, nhid, nlayers, nhead, dropout, epochs, steps_per_epoch, batch_size, bptt, lr, weight_decay, warmup_epochs, input_normalization, y_encoder_generator, pos_encoder_generator, decoder, extra_prior_kwargs_dict, scheduler, load_weights_from_this_state_dict, validation_period, single_eval_pos_gen, bptt_extra_samples, gpu_device, aggregate_k_gradients, verbose, style_encoder_generator, epoch_callback, initializer, initialize_with_model, train_mixed_precision, efficient_eval_masking, **model_extra_args)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m epochs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    249\u001b[0m     epoch_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    250\u001b[0m     total_loss, total_positional_losses, time_to_get_batch, forward_time, step_time, nan_share, ignore_share \u001b[38;5;241m=\u001b[39m\\\n\u001b[0;32m--> 251\u001b[0m         \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(dl, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidate\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m validation_period \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tabpfn/train.py:198\u001b[0m, in \u001b[0;36mtrain.<locals>.train_epoch\u001b[0;34m()\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m     losses \u001b[38;5;241m=\u001b[39m criterion(output, targets)\n\u001b[0;32m--> 198\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43mlosses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m loss, nan_share \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mtorch_nanmean(losses\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m0\u001b[39m), return_nanshare\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    200\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m aggregate_k_gradients\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[267, 16]' is invalid for input of size 4005"
     ]
    }
   ],
   "source": [
    "train_function(config_sample, 1, add_name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
