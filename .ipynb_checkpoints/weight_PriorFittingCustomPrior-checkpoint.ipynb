{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scripts.differentiable_pfn_evaluation import eval_model_range\n",
    "from scripts.model_builder import get_model, get_default_spec, save_model, load_model\n",
    "from scripts.transformer_prediction_interface import transformer_predict, get_params_from_config, load_model_workflow_my\n",
    "\n",
    "from scripts.model_configs import *\n",
    "\n",
    "from datasets import load_openml_list, open_cc_dids, open_cc_valid_dids\n",
    "from priors.utils import plot_prior, plot_features\n",
    "from priors.utils import uniform_int_sampler_f\n",
    "\n",
    "from scripts.tabular_metrics import calculate_score_per_method, calculate_score\n",
    "from scripts.tabular_evaluation import evaluate\n",
    "\n",
    "from priors.differentiable_prior import DifferentiableHyperparameterList, draw_random_style, merge_style_with_info\n",
    "from scripts import tabular_metrics\n",
    "from notebook_utils import *\n",
    "\n",
    "from tabpfn.priors.prior import PriorDataLoader\n",
    "from tabpfn.utils import get_uniform_single_eval_pos_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_datasets = True\n",
    "max_samples = 10000 if large_datasets else 5000\n",
    "bptt = 10000 if large_datasets else 3000\n",
    "suite='cc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "base_path = '.'\n",
    "max_features = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_models(model_string):\n",
    "    print(model_string)\n",
    "\n",
    "    for i in range(80):\n",
    "        for e in range(50):\n",
    "            exists = Path(os.path.join(base_path, f'smote+sq_models_diff_添加参数设置/prior_diff_real_checkpoint{model_string}_n_{i}_epoch_{e}.cpkt')).is_file()\n",
    "            if exists:\n",
    "                print(os.path.join(base_path, f'smote+sq_models_diff_添加参数设置/prior_diff_real_checkpoint{model_string}_n_{i}_epoch_{e}.cpkt'))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef train_function(config_sample, i, add_name=''):\\n    torch.cuda.empty_cache()\\n    start_time = time.time()\\n    N_epochs_to_save = 10\\n    \\n    \\n    # 经过本人更改的代码\\n    def save_callback(model, epoch):\\n        if not hasattr(model, 'last_saved_epoch'):\\n            model.last_saved_epoch = 0\\n        # 每1个批次保存一个模型\\n        if epoch % 1 == 0:\\n            config_sample['epoch_in_training'] = epoch\\n            save_model(model, base_path, f'my_models_diff/prior_diff_real_checkpoint{add_name}_n_{i}_epoch_{epoch}.cpkt',\\n                            config_sample)\\n            model.last_saved_epoch = model.last_saved_epoch + 1 # TODO: Rename to checkpoint\\n    \\n    model = get_model(config_sample\\n                      , device\\n                      , should_train=True\\n                      , verbose=1\\n                      , epoch_callback = save_callback)\\n    \\n    return\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def train_function(config_sample, i, add_name=''):\n",
    "    torch.cuda.empty_cache()\n",
    "    start_time = time.time()\n",
    "    N_epochs_to_save = 10\n",
    "    \n",
    "    \n",
    "    # 经过本人更改的代码\n",
    "    def save_callback(model, epoch):\n",
    "        if not hasattr(model, 'last_saved_epoch'):\n",
    "            model.last_saved_epoch = 0\n",
    "        # 每1个批次保存一个模型\n",
    "        if epoch % 1 == 0:\n",
    "            config_sample['epoch_in_training'] = epoch\n",
    "            save_model(model, base_path, f'my_models_diff/prior_diff_real_checkpoint{add_name}_n_{i}_epoch_{epoch}.cpkt',\n",
    "                            config_sample)\n",
    "            model.last_saved_epoch = model.last_saved_epoch + 1 # TODO: Rename to checkpoint\n",
    "    \n",
    "    model = get_model(config_sample\n",
    "                      , device\n",
    "                      , should_train=True\n",
    "                      , verbose=1\n",
    "                      , epoch_callback = save_callback)\n",
    "    \n",
    "    return\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_function(config_sample, i, add_name=''):\n",
    "    torch.cuda.empty_cache()\n",
    "    start_time = time.time()\n",
    "    max_saved_models = 50  # 保持最多保存 50 个模型\n",
    "    \n",
    "    # 定义保存模型的回调函数\n",
    "    def save_callback(model, epoch):\n",
    "        # 仅保存第 91 到第 130 个 epoch 的模型\n",
    "        if epoch < 91 or epoch > 130:\n",
    "            return  # 跳过第 101 到第 150 以外的 epoch，不保存模型\n",
    "        \n",
    "        if not hasattr(model, 'last_saved_epoch'):\n",
    "            model.last_saved_epoch = 0\n",
    "\n",
    "        # 保存当前模型\n",
    "        config_sample['epoch_in_training'] = epoch\n",
    "        save_path = f'smote+sq_models_diff_添加参数设置/prior_diff_real_checkpoint{add_name}_n_{i}_epoch_{epoch}.cpkt'\n",
    "        save_model(model, base_path, save_path, config_sample)\n",
    "        model.last_saved_epoch += 1  # 更新保存次数\n",
    "        \n",
    "        # 获取当前已保存的模型列表\n",
    "        saved_models = sorted(\n",
    "            [file for file in os.listdir(\"smote+sq_models_diff_添加参数设置\") if file.startswith(f\"prior_diff_real_checkpoint{add_name}_n_{i}_\")],\n",
    "            key=lambda x: int(x.split('_epoch_')[-1].split('.cpkt')[0])  # 按 epoch 排序\n",
    "        )\n",
    "        \n",
    "        # 保持最多保存 50 个模型，删除最早的模型\n",
    "        if len(saved_models) > max_saved_models:\n",
    "            oldest_model = saved_models[0]\n",
    "            os.remove(os.path.join(\"smote+sq_models_diff_添加参数设置\", oldest_model))  # 删除最早的模型文件\n",
    "            \n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "    # 初始化并训练模型\n",
    "    model = get_model(config_sample, device, should_train=True, verbose=1, epoch_callback=save_callback)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define prior settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def reload_config(config_type='causal', task_type='multiclass', longer=0, apply_smote=False, use_sequential_attention=False):\n",
    "    config = get_prior_config(config_type=config_type)\n",
    "    \n",
    "    config['prior_type'], config['differentiable'], config['flexible'] = 'prior_bag', True, True\n",
    "    \n",
    "    model_string = ''\n",
    "    \n",
    "    config['epochs'] = 12000\n",
    "    config['recompute_attn'] = True\n",
    "\n",
    "    config['max_num_classes'] = 2\n",
    "    config['num_classes'] = uniform_int_sampler_f(2, config['max_num_classes'])\n",
    "    config['balanced'] = False\n",
    "    model_string = model_string + '_multiclass'\n",
    "    \n",
    "    model_string = model_string + '_'+datetime.now().strftime(\"%m_%d_%Y_%H_%M_%S\")\n",
    "    \n",
    "    # 新增SMOTE和顺序注意力参数\n",
    "    #config['apply_smote'] = apply_smote\n",
    "    config['use_sequential_attention'] = use_sequential_attention\n",
    "    \n",
    "    return config, model_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualize Prior samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config, model_string = reload_config(longer=1, apply_smote=True, use_sequential_attention=True)\n",
    "\n",
    "config['bptt_extra_samples'] = None\n",
    "\n",
    "# diff\n",
    "config['output_multiclass_ordered_p'] = 0.\n",
    "del config['differentiable_hyperparameters']['output_multiclass_ordered_p']\n",
    "\n",
    "config['multiclass_type'] = 'rank'\n",
    "del config['differentiable_hyperparameters']['multiclass_type']\n",
    "\n",
    "config['sampling'] = 'normal' # vielleicht schlecht?\n",
    "del config['differentiable_hyperparameters']['sampling']\n",
    "\n",
    "config['pre_sample_causes'] = True\n",
    "# end diff\n",
    "\n",
    "config['multiclass_loss_type'] = 'nono' # 'compatible'\n",
    "config['normalize_to_ranking'] = False # False\n",
    "\n",
    "config['categorical_feature_p'] = .2 # diff: .0\n",
    "\n",
    "# turn this back on in a random search!?\n",
    "config['nan_prob_no_reason'] = .0\n",
    "config['nan_prob_unknown_reason'] = .0 # diff: .0\n",
    "config['set_value_to_nan'] = .1 # diff: 1.\n",
    "\n",
    "config['normalize_with_sqrt'] = False\n",
    "\n",
    "config['new_mlp_per_example'] = True\n",
    "config['prior_mlp_scale_weights_sqrt'] = True\n",
    "config['batch_size_per_gp_sample'] = None\n",
    "\n",
    "config['normalize_ignore_label_too'] = False\n",
    "\n",
    "config['differentiable_hps_as_style'] = False\n",
    "config['max_eval_pos'] = 1000\n",
    "\n",
    "config['random_feature_rotation'] = True\n",
    "config['rotate_normalized_labels'] = True\n",
    "\n",
    "config[\"mix_activations\"] = False # False heisst eig True\n",
    "\n",
    "config['emsize'] = 512\n",
    "config['nhead'] = config['emsize'] // 128\n",
    "config['bptt'] = 1024+128\n",
    "config['canonical_y_encoder'] = False\n",
    "\n",
    "    \n",
    "config['aggregate_k_gradients'] = 8\n",
    "config['batch_size'] = 16*config['aggregate_k_gradients']\n",
    "config['num_steps'] = 1024//config['aggregate_k_gradients']\n",
    "config['epochs'] = 130\n",
    "config['total_available_time_in_s'] = None #60*60*22 # 22 hours for some safety...\n",
    "\n",
    "config['train_mixed_precision'] = True\n",
    "config['efficient_eval_masking'] = True\n",
    "\n",
    "config_sample = evaluate_hypers(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "epoch:130\n",
      "steps_per_epoch:1024\n",
      "batch_size:16\n",
      "aggregate_k_gradients:8\n",
      "梯度下降的batch_size:128\n",
      "num_datasets:2129920\n",
      "train_mixed_precision:True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.81 M parameters\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 282.97s | mean loss  0.73 | pos losses   nan, 0.69, 0.70, 0.70, 0.68, 0.70,  nan, 0.71, 0.69, 0.70, 0.70, 0.70, 0.70,  nan, 0.70,  nan, 0.70, 0.69, 0.91, 0.70, 0.70, 5.36, 0.70,  nan,  nan, 0.70, 0.70, 0.71, 0.70, 0.69, 0.70, 0.73, 0.69,  nan, 0.69, 0.71,  nan, 0.70, 0.68, 0.70,  nan,  nan, 0.69, 0.70, 0.70, 0.70, 0.69,  nan,  nan, 0.70, 0.70, 0.69, 0.70, 0.69, 0.70,  nan, 0.70,  nan, 0.70, 0.70,  nan, 0.70, 0.69, 0.70,  nan, 0.71,  nan, 0.70,  nan, 0.70,  nan, 0.70, 0.70,  nan, 0.70, 0.70,  nan,  nan, 0.69, 0.70, 0.70, 0.69, 0.70, 0.70, 0.70, 0.69,  nan, 0.70, 0.70,  nan, 0.70,  nan, 0.70, 0.70, 0.70, 0.69, 0.81, 0.70, 0.70,  nan,  nan, 0.70, 0.70,  nan, 0.70, 0.70, 0.70, 0.70, 0.71, 0.70, 0.70, 0.70, 0.70, 0.70, 0.69,  nan, 0.70, 0.70, 0.70,  nan, 0.70, 0.69, 0.70, 0.69,  nan,  nan, 0.69, 0.69, 0.70, 0.69, 0.70, 0.69, 0.69, 0.77,  nan, 0.70, 0.70, 0.70,  nan, 0.69, 0.70,  nan, 0.69, 0.70,  nan, 0.69, 0.69, 0.70, 0.70,  nan, 0.70, 0.69, 0.70,  nan,  nan, 0.69, 0.70, 0.70,  nan, 0.70, 0.70,  nan, 0.69,  nan, 0.70,  nan,  nan, 0.97, 0.70,  nan,  nan, 0.70, 0.86, 0.70, 0.69, 0.70,  nan,  nan, 0.77,  nan,  nan, 0.69, 0.69, 0.70, 0.70, 0.70,  nan,  nan, 0.70, 0.70, 0.70, 0.70, 1.34,  nan,  nan, 0.70,  nan, 0.69, 0.70,  nan, 0.69, 0.69, 0.70, 0.70, 0.70,  nan,  nan,  nan, 0.70, 0.70,  nan,  nan, 0.70,  nan,  nan, 0.69, 0.70, 0.70,  nan,  nan,  nan, 0.69,  nan,  nan, 0.78,  nan,  nan,  nan,  nan,  nan, 0.70, 0.70, 0.70, 0.70, 0.70, 0.70, 0.69, 0.70, 0.70,  nan, 0.70,  nan, 0.70, 0.70, 0.70, 0.70, 0.70,  nan, 0.70,  nan, 0.70, 0.70, 0.69, 0.69, 2.84,  nan, 0.69,  nan,  nan, 0.70,  nan, 0.70,  nan,  nan, 0.69, 0.70, 0.70, 0.69, 0.69,  nan, 0.85, 0.70, 0.70, 0.70, 0.70,  nan, 0.70, 0.70,  nan,  nan,  nan,  nan, 0.70,  nan, 0.70, 0.70,  nan, 0.69,  nan, 0.71, 0.70,  nan, 0.70, 0.71, 0.69, 0.70, 0.70, 0.70, 0.70, 0.70, 0.70, 0.71,  nan,  nan, 0.70,  nan,  nan,  nan,  nan,  nan, 0.70, 0.69, 0.70, 0.70, 0.69, 0.69, 0.70,  nan,  nan,  nan,  nan, 0.70, 0.70,  nan, 0.70, 0.70, 0.70,  nan, 0.70, 0.70, 0.70, 0.69,  nan, 0.69, 0.94,  nan, 0.70, 0.70, 0.70, 0.70, 0.70, 0.70, 0.68,  nan, 0.70, 0.69,  nan, 0.70,  nan, 0.70, 0.70, 0.69, 0.69, 0.70, 0.69,  nan,  nan, 0.69,  nan, 0.75,  nan, 0.70, 0.70, 0.69, 0.71, 0.69, 0.69,  nan,  nan, 0.70, 0.91, 0.70, 0.69,  nan,  nan, 0.69,  nan,  nan, 0.69, 0.70, 0.70, 0.71, 0.70, 0.70, 0.70, 0.70,  nan,  nan, 0.70, 0.69,  nan, 0.70, 0.70,  nan, 0.70, 0.69, 0.70,  nan,  nan,  nan,  nan, 0.89, 0.70,  nan,  nan,  nan, 0.70,  nan,  nan,  nan,  nan,  nan,  nan, 0.70,  nan, 0.70, 0.69,  nan,  nan,  nan, 0.70, 0.69,  nan, 0.70, 0.70,  nan, 0.69,  nan,  nan,  nan, 0.70, 0.70, 4.55,  nan, 0.70,  nan, 0.69, 0.69, 0.70, 0.70,  nan, 0.70,  nan, 0.70,  nan, 0.69, 0.70,  nan, 0.64, 0.70,  nan,  nan,  nan, 0.71, 0.70, 0.70, 0.70,  nan, 0.69,  nan,  nan, 0.70, 0.68, 0.70, 0.70,  nan,  nan,  nan, 0.70,  nan, 0.70, 0.70, 0.70,  nan, 0.69, 0.70, 0.70,  nan,  nan, 0.70,  nan,  nan, 0.69, 0.70, 0.69,  nan,  nan, 0.68,  nan,  nan,  nan, 0.70,  nan, 0.70, 0.71, 0.70,  nan, 0.69,  nan, 0.70,  nan, 0.70, 0.70, 0.69, 0.70,  nan,  nan, 0.70, 0.70,  nan, 0.70, 0.70,  nan, 0.70,  nan, 0.70,  nan,  nan, 0.70, 0.70,  nan, 0.70, 0.70,  nan,  nan, 0.70,  nan, 1.34, 0.70,  nan,  nan,  nan,  nan, 0.70, 0.76, 0.70, 0.70, 0.70, 0.69,  nan, 0.69, 0.69, 0.70, 0.69,  nan, 0.69, 0.70,  nan, 0.70,  nan, 0.69, 0.71, 0.70, 0.70,  nan,  nan,  nan, 0.71,  nan, 0.70,  nan, 0.70, 0.71, 0.70,  nan,  nan, 0.76,  nan, 0.70, 0.70, 0.80,  nan, 0.69,  nan,  nan, 0.71, 0.70, 0.70, 0.70,  nan,  nan, 0.70,  nan, 0.70,  nan, 0.70, 0.70,  nan, 0.71,  nan,  nan,  nan, 0.69, 0.70, 0.70, 0.70,  nan, 0.70, 0.85,  nan, 1.01, 0.70,  nan, 0.70, 0.70, 4.03, 0.69,  nan,  nan,  nan, 0.70, 0.70, 0.70, 0.71, 0.70, 0.70, 0.70,  nan, 0.69, 0.70, 0.70, 0.69, 0.70, 0.70, 0.69, 0.70,  nan, 0.70, 0.69,  nan, 0.70, 0.70, 0.70,  nan, 0.70, 0.70,  nan, 0.70,  nan, 0.70,  nan,  nan,  nan, 0.76, 0.70,  nan,  nan, 0.70,  nan,  nan,  nan, 1.47, 0.70, 0.70, 0.70,  nan, 0.70, 0.70, 0.64, 0.70, 0.69, 0.70,  nan, 1.22,  nan,  nan, 0.69, 0.69, 0.70, 0.69, 0.73, 0.70, 0.69,  nan, 0.71, 0.69,  nan, 0.70, 0.70, 0.69, 0.69, 0.69, 0.69,  nan, 0.68,  nan, 0.70, 0.70, 0.70, 0.70, 0.71, 0.70, 0.69, 0.70, 0.70, 0.91, 0.70,  nan, 0.69,  nan, 0.69, 0.70, 0.70, 0.76,  nan, 0.69, 0.79, 0.68, 0.70, 0.69, 0.70, 0.70,  nan, 0.70, 0.70,  nan, 0.70, 0.69,  nan, 0.69,  nan, 0.70, 0.70,  nan, 0.71,  nan, 0.70, 0.69, 0.69, 0.70,  nan, 0.69, 0.70, 0.70, 0.69, 0.69,  nan,  nan, 0.69,  nan, 0.70, 0.70, 0.70, 0.70,  nan,  nan,  nan,  nan, 0.71, 0.69,  nan,  nan, 0.69, 0.69, 0.70,  nan, 0.70,  nan,  nan, 1.09, 0.69,  nan, 0.70, 0.69, 0.68, 0.70,  nan, 0.69, 0.70, 0.69, 0.77, 0.70, 0.68,  nan,  nan, 0.70,  nan, 0.70,  nan,  nan, 0.70,  nan, 0.70, 0.70, 0.71, 0.70, 0.69, 0.69, 2.36, 0.69, 0.69,  nan,  nan, 0.70, 0.78,  nan,  nan, 0.69, 2.72, 0.76, 0.69, 0.70,  nan, 0.70, 0.70,  nan, 0.70,  nan,  nan,  nan,  nan, 0.70, 0.77,  nan,  nan, 0.70, 0.70, 0.77, 0.70, 0.69, 0.69, 0.69,  nan, 0.70,  nan,  nan, 0.76, 0.70,  nan,  nan, 0.70,  nan,  nan,  nan,  nan, 0.70, 0.70,  nan, 0.70, 0.70,  nan,  nan, 0.70,  nan, 0.69, 0.70, 0.69,  nan, 0.71, 0.70, 0.69,  nan, 0.70, 0.70,  nan, 0.69,  nan, 0.70, 0.70,  nan,  nan, 0.70, 0.70,  nan, 0.70, 0.70, 0.70,  nan, 0.70, 0.70,  nan,  nan, 0.70, 0.69, 0.70, 0.70, 0.70, 0.70, 0.70, 0.70,  nan,  nan, 0.69,  nan, 0.69,  nan, 0.70, 0.69, 0.70, 0.70,  nan, 0.69, 0.69, 0.70, 0.69, 0.70, 0.70, 0.71,  nan, 0.77,  nan,  nan, 0.72, 0.69,  nan,  nan, 0.69, 0.68, 0.69, 0.70, 0.70,  nan,  nan, 0.69, 0.70, 0.70, 0.71,  nan, 0.69, 0.70, 0.70, 0.84,  nan,  nan, 0.69,  nan, 0.76, 0.69, 0.69,  nan, 0.69,  nan,  nan, 0.70,  nan,  nan, 0.70, 0.69, 0.70, 0.69,  nan,  nan,  nan,  nan, 0.81,  nan, 1.37, 0.70,  nan,  nan,  nan,  nan,  nan,  nan, 0.70, 0.69,  nan, 0.69,  nan, 0.69, 0.73,  nan, 0.70,  nan, 0.70, 0.68, 1.00, 0.70,  nan,  nan, 0.69,  nan,  nan,  nan,  nan,  nan, 0.71, 0.70, 0.70, 0.70, 0.70, 0.70, 0.69, 0.70, 0.70,  nan, 0.69, 0.70,  nan, 0.70, 0.69, 0.70, 0.69,  nan,  nan, 0.70,  nan, 0.69,  nan, 0.69,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan, lr 0.0 data time  0.11 step time  0.12 forward time  0.03 nan share  0.00 ignore share (for classification tasks) 0.0098\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 285.85s | mean loss -3.97 | pos losses  0.70,  nan,-477.26,  nan, 0.55, 0.53,  nan,  nan,  nan,  nan, 0.58,  nan,  nan, 0.60, 0.55,-22.50, 0.65, 0.52, 0.49,  nan, 0.54,-43.92, 0.59,  nan,  nan, 0.48,  nan, 0.48, 0.52,  nan, 0.57,  nan, 0.55,  nan,  nan, 0.42,  nan, 0.61,  nan,  nan, 0.52,  nan,-48.03, 0.65,  nan, 0.52, 0.59,-24.46, 0.61, 0.53, 0.50,  nan,  nan, 0.56, 0.53, 0.51, 0.50,  nan,-9.74, 0.56,-48.29,  nan,  nan, 0.66,  nan,  nan, 0.62,  nan,  nan, 0.61, 0.55, 0.59, 0.49,  nan, 0.58, 0.47,  nan, 0.68, 0.60, 0.51, 0.48, 0.67,-24.07, 0.69, 0.54, 0.52, 0.44, 0.45,  nan, 0.53, 0.46, 0.65,  nan, 0.46,  nan, 0.52,  nan, 0.55,  nan,  nan,  nan, 0.68,  nan,  nan, 0.56,  nan,  nan, 0.67, 0.61, 0.67,-38.02,  nan,  nan, 0.60, 0.62, 0.56, 0.45,  nan, 0.55,-5.27, 0.69, 0.60, 0.59, 0.50,  nan, 0.53, 0.60,  nan,  nan, 0.52, 0.57,  nan, 0.53,  nan, 0.56, 0.60, 0.52,  nan, 0.69,  nan,-21.95, 0.58,-21.39,  nan, 0.60,  nan,  nan,  nan, 0.66, 0.66, 0.48, 0.50,  nan, 0.53,-47.22, 0.62, 0.53, 0.52, 0.63, 0.50,  nan,  nan, 0.59,  nan,  nan, 0.63, 0.64, 0.48, 0.57, 0.54,  nan,  nan,  nan,  nan, 0.59, 0.58,  nan, 0.52, 0.54,  nan,  nan, 0.54,  nan,  nan, 0.52,  nan, 0.55, 0.51,  nan,  nan,  nan,  nan,  nan, 0.51,  nan, 0.52,  nan,  nan,  nan, 0.56, 0.64, 0.49,  nan, 0.43,  nan, 0.53, 0.52, 0.54, 0.53, 0.43, 0.54, 0.69, 0.67, 0.55, 0.67, 0.53,  nan, 0.46,  nan,  nan,  nan, 0.59, 0.50, 0.49, 0.61,-11.06,  nan, 0.54,  nan, 0.51, 0.51,  nan,  nan, 0.58,  nan, 0.70, 0.64, 0.45, 0.59, 0.52,  nan, 0.52, 0.60, 0.55,  nan, 0.52, 0.42, 0.37, 0.61, 0.52,  nan,  nan,  nan, 0.51,  nan, 0.54,  nan, 0.52,  nan, 0.68, 0.45, 0.62, 0.61,  nan,  nan,  nan, 0.59, 0.67, 0.55,  nan, 0.49, 0.48, 0.56, 0.56, 0.50,  nan, 0.49,  nan, 0.53, 0.54,  nan,-46.39,  nan,  nan,  nan,  nan, 0.59,  nan, 0.43,  nan, 0.55, 0.68,  nan,-44.40, 0.67, 0.45, 0.45, 0.55,  nan, 0.45, 0.57,  nan,-17.74, 0.53, 0.46, 0.47,-16.46, 0.55,-19.04,  nan,  nan, 0.45,  nan,  nan, 0.60, 0.49, 0.47, 0.49,  nan, 0.52,-10.82, 0.51,  nan,  nan, 0.55, 0.61, 0.55, 0.67,-22.96, 0.54,-16.65, 0.51,  nan, 0.53, 0.51,  nan,-44.62, 0.47,  nan, 0.58, 0.52, 0.58, 0.57,  nan,  nan,  nan, 0.55, 0.50, 0.63,  nan, 0.53, 0.52,-17.19, 0.58,  nan, 0.68,  nan, 0.42, 0.69, 0.48,  nan,  nan,  nan,  nan, 0.47, 0.49,  nan, 0.46, 0.61, 0.62, 0.47, 0.60, 0.53, 0.63,  nan, 0.59,  nan, 0.54, 0.55,  nan,  nan, 0.54,-49.99, 0.57,  nan, 0.64, 0.61, 0.47, 0.55, 0.53, 0.59, 0.48, 0.64,  nan,  nan, 0.53,  nan,  nan, 0.59,-22.79, 0.61,  nan, 0.47,  nan, 0.59, 0.43,  nan,-15.91,  nan,  nan,  nan, 0.64, 0.50,  nan, 0.69,  nan, 0.56, 0.53, 0.55, 0.54, 0.69, 0.52,  nan,  nan, 0.51, 0.57, 0.59,  nan, 0.55,-4.97,  nan, 0.69, 0.51,  nan,  nan, 0.57,  nan, 0.57, 0.53, 0.63,  nan, 0.44,  nan,-24.59, 0.54, 0.46,  nan, 0.51, 0.66, 0.51,  nan,  nan,  nan, 0.58, 0.66, 0.58,  nan,  nan, 0.51, 0.61, 0.49, 0.68,  nan, 0.45,  nan,  nan, 0.56, 0.52, 0.51, 0.67, 0.44, 0.47, 0.53,  nan,  nan, 0.56, 0.63,  nan,  nan, 0.44,  nan, 0.47,  nan, 0.47, 0.51, 0.46, 0.62, 0.58, 0.48,  nan, 0.50,  nan, 0.56,  nan, 0.68,  nan,  nan, 0.57, 0.54,  nan, 0.61,  nan, 0.48, 0.58,  nan,  nan, 0.55, 0.57,  nan,  nan,  nan, 0.45,  nan, 0.44, 0.57,  nan,  nan, 0.47,  nan,-18.08, 0.58,-42.65, 0.57, 0.53, 0.45,  nan, 0.46,  nan, 0.51, 0.46,  nan, 0.56, 0.43, 0.54, 0.40,  nan,  nan,  nan,  nan,  nan,  nan, 0.50, 0.52,  nan,  nan,  nan,-49.25, 0.46, 0.66,  nan, 0.66, 0.48,  nan, 0.58, 0.56,  nan,  nan,  nan,  nan, 0.57,  nan, 0.52, 0.48, 0.50, 0.46,  nan, 0.56,-23.64, 0.47,  nan, 0.61, 0.64, 0.50, 0.67, 0.68,  nan,  nan, 0.65, 0.54, 0.53, 0.48, 0.62,  nan,  nan, 0.47,  nan, 0.50, 0.46, 0.56, 0.52, 0.52, 0.60,  nan, 0.56,  nan,  nan,  nan, 0.53, 0.66, 0.54, 0.64, 0.68,  nan, 0.48, 0.57, 0.49, 0.54,  nan,  nan, 0.59, 0.50, 0.45, 0.45,  nan, 0.48, 0.49, 0.48, 0.49, 0.67, 0.63, 0.50, 0.53, 0.54, 0.52,  nan, 0.49, 0.50, 0.47,  nan,-42.76, 0.45,  nan, 0.45,  nan, 0.53, 0.50, 0.51, 0.64, 0.53,  nan, 0.45, 0.56,  nan, 0.56,  nan,  nan, 0.66, 0.55,  nan, 0.55, 0.56,  nan, 0.57, 0.45,  nan, 0.55,  nan, 0.55, 0.51, 0.57, 0.65,  nan,  nan,  nan, 0.36, 0.59,-13.67,-40.01, 0.63,  nan,-196.70, 0.56,  nan, 0.53, 0.52,  nan, 0.50,  nan, 0.62, 0.61,  nan,  nan, 0.43, 0.59, 0.60, 0.50,-40.04,  nan, 0.54, 0.52, 0.48, 0.52, 0.69, 0.61, 0.66, 0.57, 0.42,  nan,-1.36,  nan, 0.60,  nan,  nan, 0.46,  nan, 0.51,  nan, 0.57, 0.43, 0.60,  nan,  nan,-23.86,  nan,-13.55, 0.68,  nan,  nan, 0.54, 0.52,  nan,  nan,  nan, 0.51,  nan,  nan, 0.55, 0.66, 0.62, 0.57,  nan, 0.62,  nan, 0.66,  nan,-7.41, 0.62, 0.57, 0.61, 0.54, 0.60,-14.90, 0.63,  nan, 0.38,-42.57, 0.62,-14.63,  nan, 0.52,  nan, 0.45, 0.56, 0.58,  nan,  nan,  nan, 0.51, 0.55,  nan,  nan,-23.12,  nan, 0.54, 0.61,  nan, 0.56, 0.65,  nan, 0.47, 0.48,  nan,  nan,-16.77, 0.54, 0.69, 0.51, 0.49,  nan,  nan,  nan, 0.57,  nan,-24.67, 0.53,-115.94,  nan, 0.56, 0.48,  nan, 0.55,  nan,  nan,  nan,-17.66, 0.52, 0.59,  nan,  nan, 0.49, 0.56,  nan, 0.56, 0.61,  nan, 0.58,  nan, 0.54,-20.99,-8.81,  nan,  nan, 0.66, 0.56,  nan, 0.52,  nan, 0.68,  nan, 0.20, 0.57, 0.62, 0.45, 0.52, 0.65,  nan, 0.63, 0.51, 0.57, 0.52, 0.51, 0.66, 0.40,  nan, 0.65,  nan,  nan, 0.55, 0.61, 0.49,  nan,  nan, 0.64,  nan, 0.47, 0.52,  nan, 0.46, 0.69, 0.55,-43.52, 0.47, 0.49,  nan, 0.61,  nan,  nan, 0.46, 0.69, 0.49, 0.53, 0.48, 0.52,  nan,-11.51, 0.58, 0.50, 0.49, 0.68, 0.44,  nan, 0.49,  nan,  nan, 0.57, 0.66, 0.65, 0.43, 0.55,  nan,  nan, 0.51, 0.55, 0.51, 0.49,  nan, 0.57, 0.57,  nan, 0.49, 0.63, 0.50,  nan, 0.47, 0.51,  nan, 0.60, 0.55, 0.51,  nan,  nan,  nan, 0.66, 0.57,  nan, 0.60,  nan, 0.54, 0.52, 0.64, 0.64,  nan, 0.54, 0.50, 0.65, 0.52,  nan,  nan,  nan, 0.47,  nan, 0.27, 0.58, 0.56,  nan,  nan,  nan, 0.54,-15.61,  nan, 0.58,  nan, 0.54, 0.61,  nan,  nan,  nan,  nan, 0.53,  nan,  nan,  nan, 0.50, 0.59, 0.48,  nan,  nan, 0.57,  nan,  nan, 0.56, 0.43,  nan, 0.53, 0.60,-28.55,  nan,  nan, 0.53, 0.45,  nan,  nan, 0.53, 0.69, 0.60, 0.49, 0.67, 0.51,  nan, 0.56, 0.67,-37.82, 0.52, 0.58, 0.66,  nan, 0.58,  nan,  nan,-700.65,  nan,  nan,  nan, 0.49,  nan, 0.53, 0.53, 0.43, 0.56,  nan,  nan, 0.47, 0.57, 0.56, 0.51, 0.50,  nan, 0.46, 0.55, 0.56,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan, lr 6.965153019791294e-06 data time  0.10 step time  0.11 forward time  0.03 nan share  0.00 ignore share (for classification tasks) 0.0074\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 284.27s | mean loss -7.61 | pos losses  0.74,  nan, 0.65,  nan,-736.70, 0.58, 0.61,-83.25, 0.48,  nan, 0.54,-40.44, 0.47, 0.53, 0.56,  nan, 0.53,  nan,  nan, 0.45, 0.51, 0.46, 0.52,  nan,  nan,  nan, 0.40, 0.48,  nan, 0.41,-37.92, 0.49,  nan, 0.55, 0.50, 0.49,  nan,  nan,  nan,  nan,  nan, 0.52, 0.49,  nan,  nan, 0.53,  nan, 0.40, 0.38, 0.69, 0.54, 0.51, 0.50, 0.48, 0.34,  nan,-17.38, 0.60,  nan, 0.53,  nan,  nan, 0.33,  nan,  nan,  nan,  nan, 0.41,  nan,  nan, 0.34,  nan, 0.38,  nan, 0.28,  nan, 0.48, 0.39, 0.47,  nan,  nan, 0.45,  nan,  nan,  nan, 0.51, 0.49,  nan,  nan, 0.51, 0.48, 0.50,  nan, 0.41,  nan, 0.49,-72.62,  nan, 0.44, 0.27, 0.45, 0.49,  nan, 0.48, 0.26, 0.52, 0.51,  nan, 0.55, 0.29,  nan,  nan,-85.78,  nan,  nan, 0.51, 0.51, 0.44,  nan, 0.47, 0.41, 0.44,-23.47, 0.51,  nan,  nan,  nan, 0.51, 0.45, 0.55, 0.30,  nan,  nan,  nan,  nan,  nan,  nan, 0.43, 0.50, 0.51, 0.56, 0.38, 0.50, 0.23, 0.36, 0.50, 0.31, 0.51, 0.43,-16.91, 0.41,  nan,  nan, 0.41,  nan, 0.47,  nan, 0.47,  nan,-59.01, 0.50,  nan,  nan, 0.45, 0.41, 0.43,-34.04, 0.41, 0.46, 0.65, 0.47, 0.59, 0.47, 0.49, 0.52,  nan, 0.34,  nan, 0.52, 0.50,  nan, 0.48, 0.48,  nan, 0.47,  nan,  nan,  nan, 0.45, 0.51,-34.98, 0.55, 0.49,  nan, 0.44, 0.49,  nan, 0.35,  nan,  nan, 0.53,-87.66, 0.53, 0.47, 0.49, 0.45, 0.50, 0.56, 0.46, 0.50,  nan,  nan,-28.34,  nan,-18.33, 0.51, 0.46,-22.02,  nan, 0.48, 0.39, 0.54, 0.56,  nan,  nan, 0.44,  nan, 0.54, 0.41,  nan, 0.49, 0.48,-55.99,  nan,  nan,  nan, 0.47, 0.43,  nan,  nan, 0.52,  nan,  nan,  nan,  nan, 0.55, 0.48,  nan,  nan,  nan,-355.87,  nan, 0.50,  nan, 0.52, 0.54, 0.51,-45.07,  nan,  nan,  nan,  nan,  nan,  nan, 0.53, 0.49, 0.34, 0.42,  nan,-31.91, 0.51,  nan,-40.76,  nan, 0.40, 0.56,  nan, 0.52,  nan, 0.45, 0.45, 0.49,  nan, 0.43, 0.41,  nan, 0.49, 0.51,  nan,  nan, 0.45, 0.42, 0.48, 0.42,  nan, 0.42,  nan, 0.43,  nan,  nan,  nan,  nan,  nan, 0.49, 0.43,  nan, 0.53, 0.47,  nan, 0.41, 0.46, 0.62,  nan,  nan,  nan, 0.48,  nan, 0.48, 0.42,  nan, 0.55, 0.49, 0.53,-59.16, 0.52, 0.46, 0.53, 0.41, 0.46,  nan,  nan, 0.56,  nan, 0.57, 0.49,  nan,  nan,  nan,-17.93,  nan, 0.53, 0.47,  nan,  nan, 0.53, 0.45, 0.26,  nan,-19.47, 0.46,  nan,  nan,  nan,  nan,  nan,-27.87,  nan,  nan,-14.99, 0.60,  nan,  nan,  nan, 0.44,  nan, 0.43, 0.50, 0.28, 0.88, 0.48, 0.42, 0.42,  nan, 0.44, 0.45, 0.48,  nan, 0.54, 0.24, 0.53,  nan,  nan, 0.51,  nan, 0.39,  nan, 0.49,  nan, 0.46,  nan, 0.52, 0.49,  nan,  nan, 0.51, 0.53, 0.54, 0.40, 0.21, 0.33, 0.40,  nan, 0.46, 0.30, 0.41,  nan,  nan,  nan, 0.39,  nan, 0.53,  nan,  nan, 0.68, 0.52, 0.51, 0.56,  nan,  nan, 0.50, 0.34, 0.54,  nan, 0.53, 0.47, 0.48, 0.51, 0.48, 0.51,  nan, 0.40,  nan, 0.45, 0.47,  nan, 0.43,  nan, 0.41,  nan,  nan, 0.45, 0.55,  nan, 0.47,  nan, 0.45, 0.56, 0.52,-72.06,  nan,  nan, 0.30, 0.44, 0.45, 0.45, 0.53, 0.29,  nan, 0.55, 0.49,  nan, 0.53, 0.39,  nan,  nan,  nan, 0.56, 0.44,  nan, 0.48,  nan, 0.41,  nan, 0.55, 0.43, 0.44, 0.45,  nan, 0.45,  nan, 0.46,  nan,  nan, 0.49,  nan, 0.49,  nan,  nan, 0.49, 0.52,  nan, 0.56,  nan, 0.58,-40.20, 0.57,  nan,  nan,  nan,  nan,  nan, 0.46, 0.52, 0.42,  nan,  nan, 0.43, 0.47,  nan, 0.51, 0.51,  nan, 0.47, 0.49, 0.49, 0.45, 0.30,  nan,  nan, 0.47, 0.56,  nan,  nan,  nan, 0.45, 0.64, 0.51, 0.49,  nan,  nan, 0.50,  nan,-515.58, 0.21, 0.26, 0.51, 0.36, 0.50, 0.49, 0.53,-58.40,  nan, 0.51,  nan, 0.53, 0.48, 0.48, 0.40, 0.50,  nan,  nan, 0.50, 0.45,  nan, 0.46, 0.52,-23.95, 0.42, 0.43,  nan, 0.57,  nan, 0.44,-58.60, 0.36,-40.87, 0.42, 0.48, 0.45,-17.04, 0.43,  nan, 0.43, 0.39, 0.44, 0.53,  nan,  nan, 0.57,-121.33, 0.45,  nan, 0.47,  nan,  nan, 0.37, 0.52, 0.48,  nan,  nan,-14.98, 0.56,  nan, 0.53,  nan,  nan,  nan, 0.45, 0.49,  nan,  nan,  nan,  nan,  nan, 0.50, 0.58,  nan,  nan, 0.36, 0.42,  nan,  nan,  nan,  nan,  nan, 0.45,  nan,  nan,-34.80,  nan, 0.49, 0.56, 0.55,  nan, 0.51, 0.39,  nan, 0.30, 0.50, 0.50, 0.41, 0.52, 0.46, 0.51, 0.45,  nan, 0.50,  nan,  nan,  nan, 0.56, 0.42, 0.51, 0.51, 0.56,  nan, 0.37,-26.17,  nan,  nan, 0.51, 0.55, 0.48,  nan, 0.43, 0.53,  nan, 0.33, 0.47,  nan, 0.56,  nan, 0.51,  nan, 0.45, 0.39, 0.39, 0.51,  nan, 0.50, 0.47,  nan,  nan,  nan, 0.29, 0.33, 0.50,  nan, 0.46,  nan,  nan,-70.70, 0.28,-67.85,  nan,-35.32, 0.50,  nan, 0.57, 0.47, 0.43, 0.50,  nan, 0.34, 0.50,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan, 0.47, 0.42,  nan, 0.56, 0.32, 0.56, 0.43, 0.44,  nan, 0.47, 0.46,  nan, 0.49,  nan,  nan,  nan,  nan,  nan, 0.49, 0.32, 0.50, 0.51,  nan, 0.55,-27.13, 0.54, 0.34,  nan, 0.51,  nan, 0.53,  nan, 0.38,-74.20,  nan,  nan, 0.52,  nan, 0.41, 0.39,-55.06,  nan, 0.56, 0.52, 0.50, 0.53, 0.37, 0.43, 0.52,  nan,  nan,  nan, 0.48, 0.52,  nan,  nan,-53.36,  nan,-67.49, 0.49,  nan,  nan,  nan, 0.50, 0.50, 0.45,  nan, 0.50, 0.41,  nan,  nan, 0.54,  nan, 0.46, 0.40, 0.40, 0.52, 0.41, 0.49, 0.42, 0.56, 0.57,  nan,  nan, 0.51,  nan, 0.46,  nan,  nan,  nan, 0.57, 0.46,  nan,  nan,  nan, 0.42, 0.63,  nan, 0.48, 0.40, 0.50, 0.39, 0.48,  nan, 0.32,  nan, 0.50,  nan, 0.40,-82.17, 0.55, 0.48,  nan, 0.55, 0.51, 0.53,-52.34, 0.39, 0.55, 0.54, 0.49, 0.37,  nan,  nan, 0.42, 0.55, 0.50,  nan,  nan, 0.44, 0.46,  nan, 0.36, 0.42,-40.31, 0.53, 0.50, 0.36, 0.52, 0.48, 0.52, 0.46,-510.22,  nan,  nan, 0.51, 0.46, 0.43,  nan,  nan,  nan,  nan,  nan, 0.45, 0.50, 0.51, 0.49,  nan, 0.49, 0.39, 0.51, 0.32,  nan, 0.48, 0.50, 0.50, 0.47, 0.46, 0.48, 0.47, 0.48,  nan,-60.10,-21.94, 0.49, 0.46,-28.52, 0.45,  nan,  nan,  nan,  nan, 0.45,-76.36,  nan,  nan, 0.48,-44.20,  nan, 0.34,  nan, 0.29, 0.45,-64.39, 0.28, 0.48, 0.49,  nan, 0.50,  nan,-76.81,  nan,-29.43, 0.46, 0.52, 0.59, 0.57, 0.53, 0.38, 0.34, 0.45, 0.45, 0.57, 0.52,  nan,  nan,  nan,  nan,  nan,  nan,  nan, 0.41, 0.41, 0.33, 0.43, 0.53, 0.45,  nan, 0.48,  nan, 0.48,  nan, 0.66,  nan,  nan, 0.46,  nan, 0.55, 0.41, 0.38,  nan, 0.52, 0.47, 0.48,  nan,  nan,  nan, 0.52, 0.52, 0.45, 0.43,  nan, 0.40, 0.56,  nan, 0.55,  nan,  nan, 0.47, 0.59, 0.42, 0.49,  nan,  nan, 0.54, 0.52,  nan, 0.48, 0.48, 0.51, 0.50,  nan,  nan, 0.46, 0.70, 0.45, 0.50,  nan, 0.42, 0.45, 0.62,  nan,  nan,  nan,  nan, 0.43,  nan, 0.35,  nan,  nan, 0.46, 0.53,  nan,  nan,  nan,  nan, 0.47,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan, lr 1.3930306039582587e-05 data time  0.12 step time  0.16 forward time  0.03 nan share  0.00 ignore share (for classification tasks) 0.0070\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 290.42s | mean loss -7.14 | pos losses  1.37, 1.89, 1.16, 0.94,  nan, 0.74, 0.68, 0.57,  nan, 0.58,  nan,  nan,  nan,-97.97, 0.65,  nan, 0.48,  nan,  nan, 0.64, 0.65, 0.46,-97.93, 0.47,  nan, 0.51,  nan,  nan,  nan,  nan, 0.69, 0.33,  nan,  nan,  nan,  nan,  nan, 0.50,  nan,  nan, 0.28, 0.57, 0.50,  nan, 0.45, 0.46, 0.39, 0.53,  nan, 0.70, 0.53, 0.28,  nan,  nan,  nan,  nan, 0.78, 0.52, 0.71,  nan,  nan, 0.51, 0.48,  nan, 0.55, 0.43,  nan,  nan, 0.47,-64.09,  nan, 0.40, 0.53,  nan, 0.53, 0.49,  nan, 0.45, 0.37, 0.55, 0.56, 0.67,  nan, 0.45, 0.40,  nan, 0.50,  nan,  nan,  nan, 0.52,  nan, 0.29, 0.34,  nan, 0.42,  nan, 0.45,  nan,  nan,  nan, 0.41,  nan, 0.35,  nan, 0.52, 0.66, 0.45,-44.02, 0.21, 0.17, 0.53, 0.50, 0.51,  nan, 0.57, 0.80, 0.58,  nan, 0.40,-65.83,  nan, 0.50,-199.90,  nan, 0.47, 0.56,  nan, 0.41, 0.42,  nan,  nan, 0.38, 0.54, 0.19, 0.54,  nan, 0.20, 0.82,  nan, 0.49,  nan, 0.62,  nan, 0.40,  nan,  nan,  nan,  nan,  nan, 0.27, 0.32, 0.48,  nan, 0.26, 0.37,  nan, 0.31,  nan,  nan,  nan, 0.46,  nan, 0.52,  nan,  nan, 0.33, 0.49,-112.70, 0.49, 0.45,  nan,  nan,  nan, 0.60, 0.26, 0.49, 0.51, 0.38,-68.25, 0.49, 0.50, 0.40,  nan,  nan,  nan, 0.33, 0.53,  nan,  nan,  nan, 0.34, 0.41,  nan, 0.27, 0.29, 0.38,  nan, 0.49, 0.55,  nan,  nan,  nan, 0.33, 0.48,  nan,  nan, 0.26, 0.55,  nan, 0.48, 0.41, 0.42, 0.63, 0.49,  nan, 0.52, 0.47,  nan,  nan,  nan,  nan,  nan,  nan, 0.34,  nan, 0.27,  nan,  nan, 0.37,  nan, 0.54,  nan,  nan,  nan,  nan, 0.45,  nan,  nan,  nan,  nan,  nan, 0.54,  nan, 0.51, 0.48, 0.27, 0.81, 0.86,-37.10,  nan, 0.53, 0.51,  nan, 0.42,  nan,-116.32, 0.40,  nan,  nan, 0.39, 0.44, 0.29, 0.53,  nan, 0.44, 0.37, 0.39, 0.50,  nan, 0.58, 0.59,  nan, 0.27, 0.28, 0.53, 0.47, 0.51, 0.46,  nan, 0.52, 0.59,  nan, 0.24,  nan,  nan,  nan,  nan,  nan, 0.25, 0.47,  nan, 0.55,  nan, 0.62,  nan, 0.50, 0.43, 0.51, 0.28,  nan, 0.54, 0.53,  nan,  nan, 0.27, 0.38,  nan, 0.42,  nan, 0.52, 0.50, 0.57,  nan,  nan, 0.46, 0.37, 0.37, 0.24, 0.44,  nan, 0.43, 0.37, 0.68, 0.50, 0.30, 0.45, 0.26, 0.45, 0.55,  nan,  nan, 0.63,  nan,  nan,  nan, 0.51, 0.41,  nan, 0.48,  nan, 0.30,  nan,  nan, 0.36,  nan,  nan, 0.81,  nan, 0.51,  nan,  nan, 0.46,  nan, 0.51,  nan, 0.50,  nan, 0.44, 0.28,  nan, 0.39,  nan, 0.49, 0.45, 0.21,  nan, 0.50,  nan,  nan,  nan,  nan,  nan, 0.41, 0.55, 0.38, 0.25, 0.23, 0.43, 0.33,  nan, 0.59, 0.35, 0.49, 0.18,  nan, 0.40, 0.37, 0.33, 0.65, 0.65, 0.46, 0.47,  nan,-61.99, 0.47, 0.52, 0.39, 0.46, 0.34,  nan, 0.45,  nan, 0.15, 0.40,  nan,  nan, 0.48, 0.51,  nan,  nan,  nan,  nan, 0.49, 0.57,  nan, 0.66,  nan, 0.26, 0.26,  nan, 0.41,  nan,  nan,-26.61, 0.21,-20.72, 0.48, 0.38,  nan, 0.49,  nan,-102.09,  nan, 0.27, 0.51, 0.57, 0.30, 0.57, 0.35,  nan,  nan,-36.25, 0.26, 0.33, 0.48,  nan, 0.40,  nan,  nan,  nan,  nan,-60.67, 0.33,  nan,  nan, 0.51, 0.48, 0.53, 0.20, 0.52,  nan, 0.39, 0.29,  nan,  nan,  nan, 0.63, 0.61,  nan, 0.26, 0.52, 0.30, 0.48, 0.43, 0.48, 0.29,  nan, 0.45, 0.41, 0.39, 0.52,  nan, 0.16, 0.25,  nan,  nan, 0.48,-36.07, 0.27,  nan,  nan, 0.37, 0.32, 0.55,-23.77, 0.26,  nan, 0.38, 0.52, 0.44, 0.59,  nan, 0.47, 0.53,  nan, 0.26,  nan,  nan, 0.20, 0.59, 0.48, 0.43, 0.34, 0.45, 0.41, 0.67, 0.54,  nan,  nan, 0.69, 0.43, 0.35, 0.51, 0.40,  nan,  nan, 0.41, 0.30, 0.20, 0.61, 0.39,  nan, 0.44, 0.46, 0.37, 0.53, 0.47, 0.43,  nan,  nan, 0.49, 0.50, 0.37,-52.49, 0.32, 0.37, 0.51, 0.20,  nan,  nan, 0.45, 0.41, 0.49,  nan,  nan,  nan,  nan,  nan, 0.58,  nan, 0.56,  nan, 0.42, 0.56,  nan,  nan, 0.21, 0.59, 0.40, 0.46, 0.29,  nan,  nan, 0.24, 0.46,  nan, 0.51,-46.56,  nan,  nan,-65.53, 0.52, 0.38, 0.48, 0.39, 0.32,  nan,  nan,  nan, 0.50, 0.39, 0.37,  nan, 0.39,  nan, 0.40, 0.53,  nan, 0.41,  nan,  nan, 0.58,  nan,  nan, 0.37,  nan, 0.44, 0.57, 0.46, 0.49, 0.36,  nan, 0.42, 0.46, 0.66, 0.54,  nan, 0.27, 0.48, 0.54,  nan,-48.41,  nan, 0.50, 0.45,  nan,  nan,  nan, 0.40, 0.23,  nan,-61.41, 0.54, 0.18, 0.36, 0.16,  nan, 0.34, 0.60,  nan,  nan,  nan,  nan,  nan, 0.55,  nan, 0.44, 0.41,  nan, 0.55, 0.41, 0.46,  nan, 0.38, 0.47,  nan,  nan, 0.34, 0.39, 0.45,  nan,  nan, 0.71,  nan,  nan,  nan, 0.40,-65.77,  nan, 0.49, 0.43, 0.49, 0.29, 0.37,  nan,-47.54,  nan,-621.56, 0.56, 0.56,  nan, 0.26, 0.54,  nan, 0.51,  nan,  nan,  nan,  nan,  nan, 0.54,  nan,  nan, 0.29,  nan,  nan,-27.21,  nan,  nan,-102.85,-43.51, 0.41, 0.40,-26.01, 0.50, 0.40,  nan,  nan,  nan,  nan, 0.37,  nan,  nan,-47.70, 0.51,  nan, 0.41, 0.49, 0.43,  nan,  nan, 0.19, 0.39, 0.30, 0.65, 0.41,  nan, 0.43, 0.57, 0.25, 0.50,  nan, 0.29,  nan, 0.51, 0.43, 0.52, 0.51,  nan,-224.60, 0.22,-56.43, 0.51, 0.43,  nan, 0.39, 0.80, 0.47, 0.51, 0.44,-105.34,  nan, 0.46,  nan, 0.35, 0.46, 0.40, 0.52, 0.55,  nan, 0.43,  nan,  nan,  nan, 0.48, 0.42, 0.49, 0.56,  nan,-31.80, 0.38, 0.36,  nan, 0.29, 0.46, 0.55, 0.41,  nan, 0.21, 0.39,  nan,  nan, 0.43,  nan,  nan, 0.45, 0.24,  nan, 0.35, 0.47, 0.54, 0.50, 0.30,  nan,  nan, 0.45, 0.56, 0.48,-63.25,  nan,  nan,  nan, 0.35,  nan, 0.45, 0.31,-53.32, 0.44,-105.41, 0.42,-131.54,-44.06,  nan, 0.44, 0.49, 0.53, 0.40, 0.57,  nan, 0.26, 0.65,  nan, 0.67, 0.58, 0.45, 0.30, 0.31, 0.43, 0.36, 0.45,  nan,-109.82,  nan,  nan, 0.52, 0.36,  nan, 0.81, 0.48, 0.63, 0.54, 0.52, 0.40, 0.43, 0.20, 0.31,  nan, 0.45,  nan,  nan,  nan, 0.59, 0.37, 0.40,  nan, 0.37, 0.54,  nan, 0.53,  nan, 0.36, 0.47,  nan,  nan, 0.48,  nan,  nan, 0.43,-118.76,  nan, 0.56,  nan,  nan, 0.54, 0.44, 0.35,  nan, 0.53, 0.51, 0.39, 0.51,  nan, 0.46,  nan, 0.39,  nan, 0.53,  nan, 0.49, 0.35, 0.24, 0.67,  nan,-125.36, 0.25,  nan, 0.82, 0.46, 0.91, 0.45,  nan,  nan,  nan, 0.52, 0.57, 0.57, 0.41, 0.53, 0.39, 0.49,  nan, 0.34, 0.63, 0.32, 0.46, 0.47, 0.43, 0.49, 0.39,  nan, 0.32,-106.73,  nan, 0.53,  nan, 0.50, 0.42, 0.49,  nan,  nan, 0.49, 0.49, 0.31, 0.54,  nan, 0.47, 0.32, 0.57, 0.30,  nan, 0.37, 0.55,  nan,  nan,  nan, 0.56, 0.50,-128.50,  nan,  nan,-135.74, 0.42, 0.40,  nan, 0.52, 0.43,  nan,  nan,  nan, 0.48, 0.54,  nan,  nan,  nan, 0.43, 0.24,  nan, 0.45,  nan, 0.38,  nan, 0.42, 0.53, 0.35,  nan, 0.55, 0.47,  nan, 0.49, 0.55, 0.55, 0.56, 0.46,  nan, 0.48, 0.59,  nan, 0.32, 0.42, 0.40,  nan,  nan, 0.51,  nan,  nan, 0.54, 0.53,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan, lr 2.089545905937388e-05 data time  0.16 step time  0.18 forward time  0.03 nan share  0.00 ignore share (for classification tasks) 0.0042\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 285.27s | mean loss -13.03 | pos losses   nan, 1.42,  nan,  nan, 0.70,  nan,  nan, 0.78,  nan, 0.51, 0.77, 0.79, 0.76, 0.80, 0.58, 0.49, 0.54,  nan,  nan,  nan,  nan, 0.65, 0.40,  nan, 0.30, 0.65,-80.70, 0.38,  nan, 0.58,-147.83,  nan, 0.61,  nan,  nan, 0.47,  nan, 0.62, 0.55, 0.52, 0.34,  nan,  nan,  nan, 0.62, 0.34,  nan, 0.58, 0.29,  nan, 0.35,  nan, 0.38,-66.68,  nan,-168.43,  nan, 0.62, 0.38,-152.95, 0.42, 0.48, 0.48,  nan, 0.47, 0.59, 0.46, 0.48,  nan,  nan, 0.43, 0.49, 0.50, 0.49, 0.42, 0.32, 0.63, 0.52, 0.54,  nan, 0.59, 0.37, 0.37, 0.50,  nan, 0.48,-187.96, 0.41,  nan,  nan,  nan, 0.50,  nan, 0.43, 0.59, 0.32, 0.46, 0.49,  nan, 0.36,  nan,  nan,  nan,  nan, 0.28, 0.45, 0.43,  nan, 0.36, 0.47, 0.51,  nan,  nan, 0.46, 0.32, 0.52, 0.49, 0.44, 0.53, 0.35, 0.52,  nan, 0.52, 0.21, 0.38,  nan, 0.33, 0.35,  nan, 0.49,  nan,  nan, 0.57, 0.40, 0.44, 0.52,-69.23, 0.70, 0.35,  nan, 0.48,  nan, 0.44, 0.32,  nan,  nan, 0.32, 0.51, 0.45,  nan, 0.64,  nan,  nan,  nan,  nan, 0.54,  nan,  nan,-192.64, 0.29, 0.52,  nan, 0.23, 0.45, 0.51, 0.34,  nan, 0.31,  nan, 0.53, 0.45,  nan, 0.20, 0.42,  nan, 0.45,  nan, 0.48,  nan,  nan, 0.39, 0.46, 0.66,  nan,  nan,  nan, 0.48, 0.29, 0.45, 0.54, 0.53, 0.27,  nan,  nan, 0.45, 0.38,-75.56,  nan, 0.29, 0.49,  nan, 0.36,  nan,  nan,  nan,  nan, 0.23, 0.45,  nan, 0.36,  nan, 0.55, 0.31,  nan, 0.73, 0.40, 0.33,  nan,  nan,  nan,  nan,  nan, 0.26,  nan, 0.51,  nan, 0.36, 0.35, 0.32,  nan, 0.34,-179.61,  nan, 0.54, 0.51,  nan,  nan, 0.47,  nan, 0.49, 0.48, 0.24,-58.63, 0.56,  nan,  nan, 0.30,-171.60, 0.22,-60.91,  nan,  nan, 0.33, 0.57,  nan,-178.09,  nan, 0.16,-177.57,  nan,  nan, 0.41, 0.19, 0.41,  nan, 0.19,  nan,  nan, 0.46, 0.25, 0.26, 0.31,  nan,-47.98, 0.54, 0.29, 0.51, 0.37, 0.36, 0.54,  nan, 0.28,  nan, 0.39, 0.42, 0.44, 0.56, 0.48, 0.16, 0.52, 0.70, 0.45, 0.47, 0.54,  nan,  nan, 0.37,  nan, 0.53, 0.31,  nan,  nan,  nan, 0.46, 0.38,  nan, 0.52, 0.24, 0.12, 0.47, 0.38,-92.48, 0.16, 0.40,  nan, 0.39,  nan,  nan, 0.18, 0.31, 0.46,  nan,  nan,  nan, 0.43, 0.29, 0.27,  nan,  nan, 0.30, 0.18,  nan,  nan,  nan, 0.38,  nan,-101.18, 0.44,  nan, 0.38,  nan, 0.26, 0.36, 0.45, 0.42,  nan, 0.49,  nan, 0.14, 0.39, 0.46,  nan, 0.27, 0.37, 0.42, 0.48, 0.52, 0.27, 0.35,  nan,  nan, 0.16, 0.53,  nan,  nan,  nan, 0.56,  nan, 0.31,  nan, 0.43, 0.40, 0.48, 0.41,  nan, 0.28,-139.15, 0.39, 0.38, 0.51, 0.41,  nan,  nan,  nan, 0.30,-77.46,  nan, 0.37, 0.45,  nan, 0.51,  nan, 0.43,  nan, 0.45, 0.45,  nan,  nan, 0.27,  nan, 0.23,  nan,  nan, 0.29, 0.30,  nan, 0.44, 0.53, 0.28, 0.49, 0.38, 0.31, 0.60,  nan, 0.43, 0.36, 0.57, 0.60, 0.37,  nan,  nan,  nan, 0.50,  nan,  nan, 0.54, 0.47, 0.53, 0.42,  nan, 0.38, 0.38,  nan, 0.48,  nan, 0.46, 0.29, 0.41, 0.49, 0.47,  nan,-101.96, 0.43,  nan, 0.53,  nan, 0.34,  nan, 0.28,  nan,  nan, 0.36, 0.48, 0.49, 0.60, 0.58, 0.48,  nan, 0.19, 0.33, 0.33, 0.34, 0.33, 0.45, 0.44,  nan, 0.42,  nan, 0.16, 0.46, 0.53, 0.44, 0.26,  nan,  nan, 0.43, 0.46,  nan,  nan, 0.29,  nan,  nan, 0.51,  nan,  nan,  nan,  nan,  nan, 0.52, 0.41,  nan, 0.48, 0.35,  nan, 0.25, 0.22, 0.52, 0.41,-146.26,  nan,  nan, 0.52, 0.46,  nan,-75.62, 0.30,  nan,-179.30,  nan,  nan,  nan, 0.63,-161.39, 0.45, 0.18, 0.46, 0.26, 0.30, 0.32, 0.53, 0.14,  nan, 0.33,  nan, 0.32, 0.39,  nan, 0.52,  nan, 0.27, 0.32, 0.51, 0.30,  nan, 0.45,  nan, 0.21,  nan,  nan,  nan, 0.34, 0.18, 0.41, 0.52,  nan,  nan, 0.47,  nan, 0.39, 0.36, 0.35,  nan, 0.19,  nan, 0.39, 0.30,  nan,  nan, 0.17,  nan, 0.25,  nan, 0.50,  nan,  nan, 0.56,  nan, 0.52,  nan, 0.31,  nan,  nan, 0.39, 0.40,  nan,  nan, 0.33,  nan, 0.40, 0.41,  nan, 0.49, 0.53,  nan, 0.47, 0.44, 0.17,  nan,  nan, 0.16, 0.19,  nan, 0.34, 0.51, 0.51,  nan,  nan, 0.33,  nan,-182.16, 0.23, 0.34, 0.30, 0.44, 0.18,  nan,  nan, 0.56,  nan, 0.17, 0.48, 0.27, 0.41,  nan, 0.47, 0.49, 0.14, 0.46,  nan, 0.26, 0.40, 0.41,  nan,  nan,  nan, 0.54, 0.35, 0.29,  nan,  nan, 0.16, 0.30, 0.36,  nan, 0.20, 0.47,  nan, 0.13,  nan, 0.47,  nan, 0.51,  nan,-82.95, 0.49,  nan,-46.73,  nan, 0.48,  nan, 0.48,  nan, 0.42,  nan,  nan, 0.50,  nan,  nan, 0.37, 0.54, 0.43, 0.50, 0.37,  nan, 0.48,  nan,  nan, 0.20, 0.19, 0.58,  nan, 0.43, 0.34, 0.44,-140.86, 0.44, 0.39, 0.35, 0.37, 0.60,-95.00, 0.43, 0.38,  nan, 0.50, 0.42, 0.36, 0.53,  nan,  nan,-771.58, 0.48, 0.17, 0.39, 0.42,  nan,  nan, 0.38,-58.34,  nan,  nan, 0.54, 0.45, 0.39, 0.44,  nan, 0.36, 0.31,  nan,  nan,  nan,-98.13, 0.54,  nan, 0.37, 0.22, 0.48, 0.42, 0.46,  nan,  nan,  nan,  nan, 0.45,  nan, 0.55, 0.23, 0.46,  nan,  nan,  nan, 0.34, 0.24, 0.49, 0.23, 0.41,  nan, 0.44,  nan,  nan,  nan,  nan,-50.49, 0.46, 0.43, 0.34, 0.45, 0.13, 0.45, 0.46, 0.30,  nan, 0.39,  nan, 0.41, 0.23, 0.35, 0.36,  nan, 0.38, 0.42, 0.46, 0.47, 0.43,  nan, 0.42, 0.63,  nan,  nan,  nan, 0.55, 0.39, 0.49, 0.32, 0.49,  nan, 0.35, 0.50,  nan,  nan, 0.37,  nan, 0.55, 0.46, 0.46, 0.37, 0.36, 0.29, 0.38,  nan,-50.87, 0.28, 0.44,  nan,  nan,-167.09,-170.60, 0.20, 0.54, 0.46, 0.35, 0.26, 0.45, 0.51,-157.57,  nan, 0.32, 0.48, 0.29,-92.09, 0.49, 0.32, 0.40, 0.56, 0.13, 0.31, 0.50,  nan,-160.39,  nan, 0.23, 0.35, 0.23, 0.32,  nan,  nan, 0.36, 0.23,  nan, 0.45, 0.50,  nan, 0.23, 0.37, 0.36,  nan, 0.28,  nan,  nan, 0.19, 0.46, 0.51,  nan, 0.49,  nan,  nan,  nan, 0.16, 0.28, 0.43, 0.15, 0.23,  nan, 0.25, 0.37,  nan, 0.43, 0.48, 0.21, 0.36,  nan, 0.39, 0.37,  nan,  nan,  nan,  nan, 0.19,  nan, 0.25, 0.49, 0.42, 0.34, 0.43, 0.50, 0.50, 0.42,  nan, 0.22, 0.40,  nan,  nan, 0.38,  nan, 0.40, 0.44, 0.45, 0.55, 0.29,-188.88,  nan, 0.21, 0.54, 0.49, 0.23, 0.54, 0.52,  nan,  nan, 0.21, 0.32,-140.27, 0.44, 0.32,  nan,  nan, 0.38, 0.38,  nan, 0.46, 0.44,  nan, 0.18,-1328.56, 0.24,  nan,  nan, 0.19,  nan, 0.34,  nan,  nan,  nan, 0.36,  nan,  nan,  nan, 0.18, 0.49, 0.38,  nan, 0.18, 0.51, 0.45, 0.19, 0.39,  nan,  nan, 0.49, 0.29, 0.22, 0.33,-87.95, 0.25, 0.41,  nan, 0.49, 0.28,  nan,  nan,  nan,  nan,  nan, 0.45,  nan,  nan, 0.49, 0.23,  nan,-74.84, 0.46,-229.59,  nan,  nan, 0.20,  nan,  nan, 0.59, 0.47, 0.44, 0.46,  nan, 0.19,  nan,  nan,  nan, 0.35,  nan, 0.29, 0.25, 0.43, 0.49, 0.42, 0.44,  nan,  nan, 0.47, 0.24, 0.43,  nan, 0.48,  nan,  nan,  nan, 0.47, 0.23,  nan, 0.46, 0.21, 0.29,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan, lr 2.7860612079165175e-05 data time  0.09 step time  0.18 forward time  0.03 nan share  0.00 ignore share (for classification tasks) 0.0049\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 286.89s | mean loss -35.45 | pos losses  0.73,-114.93,  nan, 1.10, 0.83, 0.48, 0.52,  nan, 0.48,  nan, 0.83, 0.78, 0.70, 0.44, 0.86,-298.73, 0.71,-287.44, 0.69,  nan, 0.72,-80.38,  nan,  nan,  nan,  nan, 0.49,-112.89, 0.55, 0.30, 0.31,  nan, 0.45, 0.25, 0.55,-308.20,-210.23, 0.72,-62.64, 0.24,  nan,  nan, 0.54, 0.63, 0.32,  nan, 0.50,  nan, 0.53, 0.17,  nan,  nan,  nan,  nan, 0.50, 0.37,  nan,-230.03, 0.33, 0.56, 0.57,  nan, 0.25, 0.32, 0.51,  nan, 0.20, 0.29, 0.50, 0.32, 0.47, 0.21,  nan, 0.56,  nan,  nan,  nan,  nan, 0.60, 0.50, 0.49,  nan, 0.63,  nan, 0.42, 0.38, 0.15,  nan,  nan, 0.47, 0.29, 0.24,  nan, 0.60, 0.53, 0.47, 0.54, 0.42, 0.24, 0.20, 0.18,  nan, 0.17,  nan, 0.20, 0.18, 0.29,  nan, 0.43,  nan, 0.37,  nan,  nan,  nan,  nan,  nan,  nan, 0.48, 0.44, 0.17,  nan, 0.24, 0.59, 0.32, 0.16, 0.59, 0.42, 0.52,  nan,  nan, 0.27,  nan,  nan, 0.19, 0.58,  nan,  nan,  nan, 0.37, 0.41, 0.48,  nan,  nan,  nan,  nan,-255.60, 0.52, 0.57,  nan, 0.37,  nan,  nan,  nan, 0.33, 0.57,  nan,  nan, 0.59, 0.45,  nan,  nan, 0.54, 0.47,  nan, 0.16, 0.15, 0.22, 0.45,  nan, 0.27, 0.45,-3894.79, 0.54,  nan, 0.45, 0.46, 0.24,  nan, 0.17, 0.61, 0.47, 0.41, 0.51,  nan, 0.49,  nan, 0.48, 0.16, 0.38, 0.10,  nan,  nan, 0.29,  nan, 0.40,  nan, 0.50, 0.43,  nan,  nan, 0.42,  nan, 0.12, 0.50,  nan,  nan, 0.50,  nan, 0.40, 0.32,-237.29,  nan,  nan,  nan,  nan, 0.30, 0.42, 0.50, 0.31, 0.16, 0.13,  nan, 0.68, 0.46, 0.15,  nan,-319.79, 0.36, 0.36,  nan, 0.61, 0.16, 0.26, 0.42, 0.52,  nan, 0.15, 0.48,  nan,  nan,  nan,  nan,  nan,  nan,-270.22, 0.45, 0.33, 0.39,-129.36,  nan, 0.37,  nan, 0.29, 0.44,  nan, 0.13,  nan, 0.30, 0.44, 0.40, 0.33, 0.57, 0.35, 0.24,-142.58,  nan,  nan, 0.14, 0.50, 0.29, 0.46, 0.54,  nan,-260.31,  nan, 0.42, 0.46, 0.40, 0.47,  nan, 0.49, 0.21,  nan, 0.13, 0.33, 0.28, 0.51, 0.29, 0.53,  nan,-74.55, 0.24, 0.12, 0.15, 0.40,  nan,  nan,  nan, 0.13, 0.18,  nan, 0.45, 0.14, 0.49, 0.38, 0.51,  nan, 0.32,  nan, 0.24, 0.42, 0.54, 0.46,-283.35,  nan, 0.30, 0.40,  nan, 0.56,  nan,  nan, 0.52,  nan,  nan,  nan, 0.42, 0.46, 0.48, 0.43, 0.39, 0.13, 0.36, 0.32, 0.47,-214.02, 0.43,  nan, 0.34,  nan,  nan,  nan,  nan,  nan, 0.20, 0.52, 0.52,  nan, 0.41,  nan,  nan, 0.51,-55.98,  nan, 1.24,  nan,  nan,  nan, 0.45, 0.40, 0.18,  nan, 0.55,  nan,  nan, 0.38,  nan,-41.87, 0.18, 0.55, 0.18, 0.20, 0.42, 0.33, 0.31,  nan, 0.39, 0.31, 0.52, 0.46,-116.85, 0.60, 0.41,  nan, 0.42, 0.56, 0.51,  nan, 0.33, 0.30, 0.70,  nan, 0.43, 0.56, 0.45, 0.32, 0.40,  nan, 0.36, 0.33,  nan,  nan, 0.52, 0.36, 0.40, 0.48,  nan,  nan, 0.38,  nan, 0.46, 0.44,  nan, 0.46, 0.45,  nan, 0.47,  nan, 0.46, 0.33,  nan,  nan, 0.14, 0.44, 0.36, 0.49,  nan, 0.49,  nan, 0.63,  nan, 0.27, 0.45, 0.42, 0.37, 0.47, 0.52, 0.50, 0.45,  nan,  nan,  nan,  nan, 0.58, 0.41,  nan, 0.44, 0.61, 0.47, 0.37, 0.17, 0.33, 0.50, 0.46, 0.24, 0.13,-101.13, 0.62,  nan,  nan, 0.68, 0.47, 0.47, 0.48, 0.39, 0.32,-263.58,  nan,-4893.75,  nan,  nan,  nan,  nan, 0.40, 0.39, 0.30, 0.19,  nan,  nan, 0.38,  nan,  nan,  nan,  nan,  nan, 0.32,  nan, 0.38, 0.45,  nan, 0.60,  nan,-97.58,-283.30,  nan,-77.18, 0.33, 0.14, 0.46, 0.26,-272.80,  nan,  nan, 0.42, 0.28,-56.95,  nan,  nan,  nan, 0.37, 0.33, 0.43,  nan, 0.14, 0.49, 0.25, 0.50,  nan,  nan,  nan, 0.49, 0.42, 0.36,  nan, 0.48, 0.28,  nan,  nan,  nan, 0.50, 0.51,  nan,-168.50,  nan, 0.62, 0.42, 0.45,  nan, 0.48, 0.45,  nan, 0.54, 0.30,  nan, 0.48, 0.51,  nan, 0.12, 0.31, 0.22, 0.40, 0.46,  nan, 0.22, 0.43,  nan, 0.32, 0.14,  nan,  nan,  nan, 0.17,  nan, 0.27,  nan, 0.58,-217.61, 0.58, 0.40,  nan, 0.31, 0.39, 0.30, 0.35,  nan, 0.36, 0.16,-318.79,  nan,  nan, 0.26,  nan, 0.59, 0.44, 0.48,  nan,  nan,  nan, 0.35, 0.34,  nan, 0.39, 0.51, 0.35,  nan,  nan,  nan,  nan, 0.30, 0.19, 0.13,-4478.46, 0.18,-299.30, 0.46, 0.39, 0.45,  nan, 0.25, 0.48,  nan, 0.39,-104.17, 0.54, 0.14, 0.44, 0.43,  nan,  nan, 0.30, 0.43,  nan, 0.41,  nan, 0.12, 0.27, 0.21, 0.51,  nan,-83.82, 0.44, 0.46, 0.22, 0.15, 0.42,  nan, 0.58,  nan, 0.29, 0.37,-315.09,  nan,  nan,  nan, 0.44,  nan, 0.14, 0.25, 0.51,  nan,  nan, 0.38,  nan, 0.50, 0.38, 0.49, 0.43,  nan, 0.50, 0.17,  nan,  nan,-89.27,-166.60,  nan, 0.59,-220.97, 0.53, 0.47,  nan, 0.40, 0.47, 0.50, 0.26,  nan, 0.44, 0.15,  nan, 0.41, 0.32,  nan, 0.13,  nan,  nan,  nan,  nan,  nan, 0.18,  nan, 0.62, 0.50,  nan, 0.41, 0.39, 0.50, 0.28, 0.36, 0.45,  nan,-301.76, 0.14,  nan, 0.28, 0.47,  nan, 0.43,  nan, 0.35, 0.69,  nan,  nan, 0.44, 0.18, 0.27,  nan, 0.19, 0.58, 0.41, 0.48, 0.35,  nan,  nan,  nan,  nan,  nan, 0.49, 0.50, 0.25,  nan,  nan,  nan,  nan,-191.57,  nan,  nan,  nan, 0.38,-247.11,  nan, 0.14, 0.23, 0.18, 0.36, 0.21, 0.26,  nan,  nan,  nan,  nan,  nan,  nan,  nan, 0.47,  nan, 0.30,  nan,  nan,  nan, 0.49, 0.35,  nan,  nan, 0.20, 0.45, 0.24, 0.45, 0.33, 0.39, 0.42,  nan,-236.05,  nan,  nan,  nan, 0.35,  nan, 0.35, 0.21,  nan, 0.47,  nan,  nan,  nan, 0.48,  nan, 0.52,  nan, 0.44, 0.40,  nan,  nan, 0.50,  nan, 0.47, 0.41,  nan, 0.35,-167.72, 0.15, 0.42, 0.38, 0.28, 0.25, 0.38,  nan,  nan, 0.43, 0.43, 0.33, 0.40, 0.46, 0.43, 0.44, 0.43, 0.35, 0.40, 0.30,  nan,-275.20, 0.46,  nan, 0.12,  nan, 0.39, 0.17, 0.37, 0.38,  nan, 0.50,  nan, 0.32, 0.31, 0.51,  nan, 0.35, 0.38,  nan,-627.81, 0.12, 0.28,  nan, 0.45,  nan,  nan, 0.40, 0.25,  nan,-70.65, 0.42, 0.30,  nan, 0.53, 0.16, 0.14, 0.33, 0.28,  nan, 0.39,-134.11, 0.40,-139.99, 0.42,  nan, 0.35,  nan,-147.46,  nan, 0.36,-145.43,  nan, 0.45,-120.17, 0.50, 0.39,  nan, 0.53,  nan,  nan,  nan, 0.39, 0.35, 0.43,  nan, 0.17, 0.42, 0.40,  nan,  nan, 0.17, 0.36, 0.48,  nan, 0.39,  nan, 0.23, 0.33,  nan, 0.48, 0.40, 0.50, 0.46,  nan,  nan,-159.00,  nan,  nan, 0.54, 0.31, 0.14, 0.45,-77.57, 0.23, 0.39, 0.46, 0.51,  nan,  nan, 0.24, 0.47,  nan,  nan,-268.42, 0.32, 0.46, 0.49, 0.45, 0.14,  nan,  nan,  nan,  nan, 0.43, 0.38,  nan,  nan, 0.17, 0.55, 0.48,  nan, 0.26, 0.52, 0.31,  nan,  nan,  nan, 0.33, 0.37, 0.34,  nan,  nan, 0.20, 0.53, 0.48, 0.30, 0.27,-82.51, 0.46, 0.49,  nan, 0.49,-2548.37,  nan, 0.39, 0.40, 0.57, 0.43, 0.52, 0.44,  nan, 0.58,-145.13, 0.49, 0.36,  nan, 0.52, 0.51, 0.31,  nan, 0.46, 0.55,  nan,  nan, 0.12,  nan,  nan,-270.37,-108.93, 0.17,-145.73, 0.49,  nan,  nan, 0.27,  nan,  nan,  nan, 0.47, 0.17, 0.47, 0.21, 0.43,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan, lr 3.4825765098956466e-05 data time  0.11 step time  0.20 forward time  0.03 nan share  0.00 ignore share (for classification tasks) 0.0081\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 281.48s | mean loss -58.26 | pos losses  0.78,  nan,  nan, 1.06,  nan, 0.85,  nan,  nan, 0.38,  nan,  nan, 0.57,-315.75,  nan, 0.89, 0.54, 0.53, 0.68,-411.90, 0.74,  nan, 0.56, 0.60,  nan,-401.78, 0.62, 0.73, 0.75, 0.19, 0.43,  nan, 0.26, 0.61,  nan, 0.38,  nan, 0.22,-419.76, 0.54, 0.69, 0.64,-465.39, 0.97,  nan,  nan, 0.55,-189.17,  nan, 0.43,  nan,  nan, 0.51, 0.23,  nan, 0.45, 0.36, 0.37, 0.20,  nan,  nan, 0.46, 0.67,  nan, 0.71, 0.44, 0.77,  nan, 0.34,  nan, 0.18, 0.28,  nan, 0.54,  nan, 0.18, 0.49,  nan,  nan,  nan, 0.28,  nan,  nan, 0.53, 0.43,  nan,  nan,  nan, 0.52, 0.12,  nan, 0.49, 0.61,  nan, 0.40, 0.66, 0.14, 0.40,  nan,-352.27, 0.48, 0.56, 0.15, 0.39, 0.53, 0.51,-390.14,  nan,  nan, 0.41,  nan, 0.53,  nan, 0.56, 0.42, 0.30, 0.36,-112.72,  nan,  nan, 0.54, 0.18, 0.44,-123.80,-188.93,  nan, 0.47,  nan,  nan,  nan,  nan, 0.46,  nan, 0.48,  nan,  nan,  nan,  nan,  nan, 0.46, 0.41, 0.33,  nan, 0.46,-450.28, 0.22,  nan,  nan,  nan, 0.43, 0.46, 0.55,  nan, 0.28, 0.47, 0.36, 0.33,-123.33, 0.61, 0.48, 0.15,  nan,-116.17, 0.26, 0.51, 0.25, 0.25,  nan, 0.33,  nan,  nan, 0.38, 0.48,  nan, 0.24, 0.29, 0.55,-7548.91, 0.15, 0.39,  nan, 0.19, 0.11,  nan,  nan, 0.58, 0.25,  nan, 0.53, 0.21,  nan, 0.58, 0.10, 0.38, 0.35, 0.55,  nan, 0.37, 0.51, 0.42, 0.37,  nan, 0.31,  nan, 0.50, 0.52, 0.50, 0.49,  nan, 0.22, 0.45,-415.90, 0.46,  nan, 0.47, 0.57,  nan, 0.49, 0.48,  nan,  nan, 0.47, 0.20,  nan, 0.42,  nan,  nan, 0.13, 0.21,  nan, 0.42,  nan, 0.49,  nan, 0.73, 0.45,  nan,-371.27, 0.56, 0.45, 0.49, 0.51, 0.28,  nan,  nan, 0.46, 0.32, 0.19, 0.42, 0.25,  nan,-162.72,-178.83,  nan,  nan, 0.22, 0.59, 0.51,-390.02, 0.45, 0.29, 0.28, 0.54,-195.08, 0.45,  nan, 0.36,  nan, 0.53, 0.52, 0.38,  nan, 0.42, 0.48, 0.31, 0.49, 0.44, 0.31, 0.45, 0.14,  nan, 0.44, 0.16, 0.13, 0.51, 0.31, 0.56,  nan, 0.17,  nan, 0.31,-189.51, 0.16, 0.46, 0.14,  nan,  nan, 0.50, 0.27,  nan,  nan, 0.30,  nan,  nan, 0.41,  nan,  nan,  nan, 0.34, 0.43,  nan,  nan,-359.57,-227.22, 0.31, 0.17,  nan,  nan,  nan, 0.29,  nan,  nan, 0.23, 0.41, 0.39, 0.17,  nan,  nan,  nan, 0.40,  nan, 0.19, 0.15, 0.46,  nan,-116.02,  nan,  nan,  nan, 0.39, 0.66,  nan, 0.58, 0.48, 0.48, 0.51, 0.43, 0.49, 0.42,  nan, 0.46, 0.45, 0.35, 0.43, 0.38, 0.39,  nan,  nan, 0.12, 0.41, 0.55, 0.54, 0.42,  nan, 0.33, 0.46, 0.40, 0.52,  nan,-74.24,  nan, 0.18, 0.37, 0.45,  nan, 0.51,  nan, 0.32, 0.40,  nan, 0.36, 0.28, 0.56, 0.35,  nan, 0.69, 0.20,  nan, 0.50,-453.45, 0.36, 0.53,  nan, 0.16,  nan, 0.46, 0.50, 0.64,  nan, 0.58,  nan, 0.23, 0.44,  nan, 0.47, 0.33,  nan,  nan, 0.13,  nan,  nan, 0.53, 0.64,  nan, 0.53,  nan,  nan, 0.59, 0.34, 0.62, 0.36,  nan,  nan,-139.90, 0.59,  nan, 0.36, 0.54,  nan, 0.36,  nan,  nan,  nan,  nan,  nan, 0.29,  nan,-412.08,  nan,  nan, 0.42,  nan, 0.44,  nan, 0.12, 0.52,  nan,  nan,  nan, 0.55,-86.03, 0.36,  nan,-361.16, 0.34, 0.17,  nan, 0.25, 0.50, 0.31, 0.59, 0.41,  nan, 0.31,  nan, 0.17, 0.32, 0.31, 0.41, 0.39,-189.05,-433.25, 0.52, 0.47, 0.48,-349.19, 0.48, 0.53,  nan, 0.54, 0.39, 0.43, 0.49, 0.36, 0.41,  nan, 0.54, 0.52, 0.38, 0.16,-171.17,-161.29,-172.63, 0.34, 0.13,  nan,  nan, 0.38, 0.41, 0.43, 0.43,  nan,  nan, 0.32, 0.52, 0.49,  nan, 0.48,  nan, 0.12,  nan, 0.28,  nan, 0.35,-471.83,  nan,  nan,  nan, 0.29,-451.88, 0.46, 0.36,  nan, 0.41, 0.36,  nan, 0.59, 0.22,  nan, 0.40, 0.48, 0.48, 0.55, 0.32, 0.29, 0.46,  nan, 0.44,  nan, 0.47,  nan, 0.34,  nan,  nan, 0.45, 0.36,  nan, 0.38,  nan,  nan, 0.46, 0.16, 0.43, 0.39,  nan, 0.56, 0.41, 0.42, 0.38,-228.02, 0.51, 0.45,  nan,  nan,  nan, 0.50, 0.51, 0.27, 0.56, 0.49, 0.31,  nan, 0.48,  nan, 0.38, 0.12,  nan,  nan, 0.63, 0.34, 0.20, 0.22, 0.10,  nan,  nan,  nan, 0.56, 0.12,  nan, 0.36,  nan, 0.51, 0.44, 0.37,  nan,-128.00, 0.31, 0.47,  nan,  nan, 0.26,  nan, 0.13, 0.44, 0.26,  nan,  nan,  nan, 0.50,  nan, 0.54,  nan, 0.27, 0.51, 0.46,  nan, 0.39, 0.45,  nan, 0.69,-213.78,  nan, 0.39,-138.81,  nan,-423.14, 0.32, 0.50,  nan, 0.34,  nan,  nan,  nan, 0.33,  nan, 0.52,  nan, 0.45, 0.31, 0.24,  nan, 0.38,  nan, 0.44, 0.74,  nan, 0.41,  nan, 0.45, 0.41, 0.22, 0.16, 0.55, 0.38, 0.69,  nan, 0.45,  nan,  nan, 0.34,  nan, 0.31,  nan,  nan,  nan, 0.49,  nan, 0.51,  nan,  nan,  nan, 0.25, 0.13,  nan,  nan,-119.79,  nan,-203.87, 0.37, 0.23,  nan, 0.48,  nan, 0.59, 0.21, 0.48,  nan, 0.31, 0.46,  nan, 0.41,  nan,  nan,  nan, 0.37, 0.14, 0.27,  nan, 0.40, 0.35,  nan,  nan, 0.34, 0.17, 0.58, 0.49,  nan, 0.24,  nan,-6076.25,  nan,  nan,-456.52, 0.31,  nan,  nan,-199.40, 0.51,-222.37, 0.37, 0.44,  nan, 0.35, 0.37, 0.39,  nan, 0.53, 0.37, 0.16, 0.27, 0.15, 0.10,  nan,  nan, 0.23, 0.39,  nan,  nan, 0.52,  nan,  nan, 0.14, 0.12, 0.41,  nan, 0.21,  nan,  nan, 0.49,  nan,-3668.73, 0.53, 0.13,  nan, 0.33,  nan, 0.51, 0.34,  nan,-369.55,  nan, 0.40, 0.56, 0.51,  nan, 0.17, 0.17, 0.52,  nan, 0.40, 0.42, 0.51, 0.42, 0.51,-370.96, 0.49, 0.17, 0.29, 0.52, 0.46,  nan,  nan, 0.28, 0.56,  nan, 0.53,  nan, 0.32,  nan, 0.49,  nan,  nan, 0.33, 0.47, 0.68,  nan, 0.48,  nan,-171.28,  nan, 0.46, 0.41, 0.50, 0.14,  nan,  nan,  nan, 0.19,  nan, 0.23, 0.37, 0.23, 0.48, 0.45, 0.26, 0.44, 0.45,  nan, 0.42,  nan,  nan,-477.23,  nan,  nan, 0.13,  nan, 0.26, 0.45, 0.52, 0.46,  nan,  nan, 0.53, 0.41, 0.34, 0.38, 0.41,  nan, 0.37,-488.68, 0.12,  nan,  nan, 0.20, 0.26, 0.13, 0.43, 0.32, 0.12, 0.35,  nan,  nan, 0.46,  nan,  nan, 0.34, 0.52,-222.39,  nan,-96.49, 0.49, 0.52,-450.55, 0.35, 0.47,  nan,  nan,  nan,  nan,  nan,  nan,  nan, 0.53,  nan, 0.39, 0.44, 0.51, 0.32, 0.48,-3130.47,  nan, 0.48,  nan, 0.42,  nan,  nan, 0.25, 0.48, 0.34, 0.49,  nan,  nan, 0.25,  nan, 0.42,-6062.03, 0.46,  nan, 0.38,  nan,  nan,  nan, 0.50,  nan,  nan, 0.46, 0.24, 0.29, 0.23, 0.41, 0.41, 0.45, 0.15,  nan, 0.57, 0.22,  nan, 0.33, 0.44,-347.86, 0.46, 0.33, 0.55,  nan,-438.34, 0.53, 0.32,  nan,  nan,  nan,  nan, 0.13,  nan, 0.30,  nan, 0.13,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan, 0.20,  nan,  nan,  nan, 0.28,  nan, 0.16, 0.16,-143.04,  nan, 0.26, 0.62, 0.37, 0.48, 0.54,  nan, 0.32, 0.43,  nan, 0.38,  nan,  nan, 0.23, 0.52,  nan, 0.46, 0.32, 0.52, 0.43, 0.49,  nan, 0.27, 0.74, 0.46, 0.23, 0.39,  nan,  nan, 0.48,  nan, 0.12, 0.29, 0.36, 0.12,  nan, 0.43,  nan,  nan, 0.30,  nan,  nan,  nan, 0.52, 0.45, 0.18,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan, lr 4.179091811874776e-05 data time  0.09 step time  0.11 forward time  0.03 nan share  0.00 ignore share (for classification tasks) 0.0089\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 285.96s | mean loss -61.09 | pos losses   nan, 1.42,  nan,  nan,  nan, 0.77, 0.88, 0.56,  nan,  nan,  nan, 0.61,  nan, 0.67,  nan, 0.84,  nan,  nan, 0.68, 0.82, 1.01, 0.65,-619.51,  nan, 0.23,  nan, 0.79, 0.69, 0.56, 0.66,-602.46,  nan, 0.56,  nan,  nan, 0.41, 0.51,  nan, 0.69, 0.68,-180.30, 0.53,  nan,-262.39,  nan,  nan, 0.53, 0.15, 0.33, 0.80,  nan, 0.44,  nan, 0.51, 0.45, 0.29, 0.54,  nan, 0.43,-8043.70, 0.67,  nan, 0.54,  nan,  nan, 0.49, 0.13, 0.69, 0.64,  nan, 0.41, 0.49,-634.47,  nan,-5507.27, 0.37, 0.49, 0.19,  nan, 0.42, 0.57, 0.54, 0.13,  nan,  nan,  nan,  nan, 0.18, 0.80, 0.46, 0.34,  nan,  nan,  nan, 0.48, 0.29,  nan, 0.48, 0.42,  nan, 0.49, 0.53, 0.16,  nan,  nan, 0.25,  nan,  nan, 0.17,  nan,  nan,  nan,-291.95, 0.37, 0.14,  nan, 0.46, 0.53, 0.29,  nan, 0.43, 0.43,-544.12, 0.77,  nan,  nan, 0.42, 0.47, 0.27, 0.17, 0.45,  nan, 0.49,  nan, 0.15,  nan, 0.47,  nan, 0.47,  nan,  nan, 0.11, 0.48, 0.26,-146.19,-303.31,  nan,  nan, 0.54,  nan,  nan, 0.55, 0.13,-643.68, 0.40, 0.35,  nan,  nan, 0.41, 0.15, 0.47, 0.32, 0.64,  nan, 0.53, 0.57,  nan, 0.40,  nan,  nan, 0.59, 0.54, 0.62,  nan, 0.17, 0.63, 0.39,  nan, 0.69, 0.28, 0.44,  nan,  nan, 0.22,  nan,  nan,  nan,  nan, 0.36, 0.23, 0.36, 0.18,  nan, 0.57, 0.27, 0.36,  nan, 0.56,-673.53,  nan, 0.44, 0.41, 0.54, 0.71, 0.55,  nan,  nan,  nan,  nan,  nan, 0.46, 0.36,  nan,  nan,  nan,  nan, 0.26, 0.39, 0.43, 0.18, 0.31, 0.38, 0.49,-578.21,-329.58, 0.41,  nan, 0.26, 0.31, 0.35,  nan,  nan, 0.39,  nan,  nan, 0.49, 0.36, 0.27, 0.40, 0.35, 0.15,  nan, 0.34,  nan,-322.23,  nan,  nan, 0.51, 0.26, 0.26, 0.43,  nan,  nan, 0.19,  nan, 0.28, 0.44, 0.45,  nan, 0.14, 0.09,  nan,  nan,  nan,  nan,  nan, 0.62,  nan, 0.25,-899.97, 0.43,-315.51,  nan, 0.25, 0.39,  nan,  nan,  nan, 0.44, 0.48, 0.09,  nan,  nan, 0.21,  nan, 0.43, 0.30,  nan, 0.40,  nan,  nan, 0.58, 0.44, 0.42, 0.30, 0.62,  nan, 0.44,  nan, 0.15,  nan,  nan,  nan,  nan,  nan, 0.50, 0.29,  nan,  nan,  nan, 0.41,  nan, 0.47, 0.43,  nan, 0.45, 0.58, 0.31,  nan, 0.49,-136.86,  nan, 0.45, 0.44, 0.46,  nan, 0.52,  nan,  nan, 0.37, 0.39, 0.24, 0.62, 0.34, 0.51, 0.38, 0.30,  nan,  nan, 0.62,  nan,  nan,  nan,  nan, 0.53, 0.28, 0.32, 0.50,  nan,  nan, 0.24,  nan,  nan,  nan, 0.22, 0.55, 0.35, 0.15, 0.40, 0.44, 0.68,  nan,  nan,  nan, 0.40,  nan, 0.42,  nan,  nan,  nan, 0.53,  nan, 0.52, 0.42,  nan,  nan,  nan,  nan,  nan, 0.54, 0.31, 0.32,  nan, 0.32,  nan,  nan, 0.32, 0.47, 0.43, 0.21, 0.09,  nan, 0.16,  nan, 0.40,  nan, 0.51,-224.34, 0.55, 0.42, 0.41,  nan,  nan, 0.39, 0.36,  nan,  nan,-532.09,  nan, 0.38,-1096.66, 0.70, 0.49,  nan, 0.42,  nan, 0.49,  nan, 0.34, 0.48, 0.33, 0.43,  nan, 0.28, 0.16,  nan, 0.30, 0.23, 0.46, 0.17, 0.16, 0.45, 0.40,  nan,  nan, 0.38,  nan, 0.47, 0.71, 0.39, 0.12, 0.19, 0.41,-563.89,  nan,-527.03,-267.78, 0.36, 0.31, 0.51,-148.55,  nan,  nan, 0.53,  nan, 0.39, 0.22,  nan, 0.31, 0.47, 0.44, 0.20,  nan, 0.41,  nan, 0.38, 0.51,  nan, 0.35, 0.55,  nan,  nan,  nan, 0.57, 0.14,  nan,  nan, 0.37, 0.34, 0.16, 0.13,  nan, 0.50, 0.42,  nan, 0.43,  nan,  nan,  nan, 0.44,  nan,  nan, 0.30, 0.27, 0.40, 0.41, 0.52, 0.20,  nan, 0.28,  nan, 0.12, 0.28, 0.42, 0.24, 0.18, 0.52, 0.37,  nan,  nan, 0.14, 0.29, 0.43,-285.89, 0.11, 0.62, 0.42, 0.48, 0.47, 0.34,  nan,  nan, 0.23,  nan,  nan,  nan, 0.11, 0.57,  nan, 0.26,  nan, 0.34,  nan,  nan, 0.18, 0.38,  nan, 0.56, 0.22, 0.42, 0.48,  nan,  nan, 0.65, 0.44,  nan,  nan,  nan,  nan, 0.31,-255.27, 0.46, 0.46, 0.41, 0.59, 0.28, 0.12,  nan, 0.48, 0.48,  nan,  nan, 0.16, 0.53, 0.45, 0.57,  nan, 0.39,  nan, 0.50,  nan, 0.21, 0.43, 0.38,  nan, 0.15, 0.47, 0.48, 0.38,  nan, 0.54, 0.13, 0.37,  nan,  nan,  nan, 0.34,  nan, 0.18, 0.43, 0.26,  nan, 0.44,  nan, 0.17,-609.71,  nan, 0.14,  nan, 0.37, 0.54, 0.39, 0.61, 0.49,  nan, 0.52,  nan, 0.10,  nan, 0.15,  nan, 0.43, 0.18, 0.31, 0.42,  nan,  nan, 0.51, 0.55, 0.10,  nan, 0.69, 0.41,  nan, 0.12, 0.27,  nan, 0.14, 0.49,  nan,  nan,  nan,  nan, 0.07,  nan, 0.10,  nan, 0.32, 0.38, 0.40,  nan, 0.34, 0.16, 0.31,  nan,  nan, 0.30,  nan,  nan, 0.11, 0.41, 0.39, 0.46, 0.36, 0.53, 0.15, 0.58, 0.32,-221.14, 0.14, 0.56, 0.22, 0.17,  nan, 0.50,  nan,-279.22,  nan, 0.19,  nan,  nan, 0.39, 0.41, 0.36,  nan, 0.34, 0.54, 0.53, 0.38,-157.01, 0.46, 0.12,  nan, 0.27,  nan,  nan, 0.53,-281.30, 0.31, 0.42, 0.52, 0.39, 0.34,-672.09, 0.17,  nan,  nan,  nan,  nan,  nan, 0.51, 0.46, 0.42, 0.38,  nan,  nan,-624.47,  nan, 0.61, 0.27,  nan, 0.33,  nan,-325.86, 0.47, 0.45, 0.29,-262.35,-202.07,  nan,  nan, 0.32,  nan,  nan, 0.09, 0.17,  nan, 0.59, 0.42,  nan, 0.30, 0.50, 0.53, 0.13, 0.29, 0.40, 0.48, 0.13, 0.37, 0.48, 0.24,  nan,  nan, 0.36,  nan,-259.09,-591.35, 0.50,  nan,  nan, 0.47, 0.31,  nan, 0.44,  nan, 0.17, 0.44,-294.09, 0.45, 0.28, 0.14,  nan, 0.54, 0.37, 0.17,  nan,  nan,  nan, 0.45, 0.28,  nan, 0.33,  nan,  nan, 0.55,  nan, 0.20, 0.23, 0.38,  nan,  nan, 0.50, 0.37, 0.50,  nan,-138.85,  nan, 0.49,-335.88,  nan, 0.42,  nan,  nan, 0.16, 0.45,-506.51,  nan, 0.38, 0.48,  nan,  nan,-138.95,  nan, 0.13,  nan, 0.30,  nan, 0.50,  nan, 0.34, 0.37, 0.47,  nan, 0.28,-514.01, 0.38,-612.63,-615.14, 0.47,  nan, 0.30, 0.48, 0.34, 0.30,-673.66, 0.41, 0.51,  nan, 0.35, 0.30,  nan, 0.46,-540.62, 0.27, 0.54,  nan, 0.28,  nan,  nan, 0.11, 0.40,  nan,  nan, 0.55,-304.85, 0.48,  nan, 0.34,  nan,  nan, 0.40,  nan, 0.48, 0.39,-649.04, 0.51,  nan, 0.31, 0.40,  nan, 0.26, 0.62, 0.32,  nan,  nan,  nan, 0.48,  nan, 0.37, 0.16,  nan, 0.60,-302.24, 0.37,  nan,  nan, 0.60,  nan,  nan, 0.34, 0.34, 0.36,-644.97, 0.27, 0.14,  nan,  nan,  nan, 0.28,  nan, 0.73,  nan, 0.44, 0.07, 0.27, 0.29, 0.12, 0.60,  nan, 0.64,  nan,  nan, 0.47,-314.48,  nan,-167.38,  nan,  nan, 0.39, 0.47,-673.70, 0.12,  nan, 0.29, 0.17, 0.30, 0.59, 0.12,  nan,  nan, 0.51,  nan,  nan, 0.39,  nan, 0.42,  nan,  nan, 0.42,  nan,  nan, 0.18,  nan,-662.04,  nan, 0.44, 0.33,  nan, 0.15, 0.53,  nan,  nan, 0.33, 0.47,  nan, 0.19, 0.34,  nan,  nan,  nan,  nan, 0.08, 0.48, 0.53,-258.37,  nan, 0.44, 0.43, 0.47, 0.12, 0.15, 0.45, 0.31, 0.65, 0.48, 0.33, 0.48,  nan, 0.55, 0.42,  nan, 0.38, 0.28, 0.43, 0.16,  nan, 0.58, 0.25, 0.41, 0.21, 0.35, 0.24, 0.51,-5318.27, 0.46, 0.46,  nan, 0.42, 0.20,  nan, 0.46, 0.28,  nan, 0.44,  nan, 0.79,  nan, 0.32,  nan,-203.64,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan, lr 4.875607113853905e-05 data time  0.15 step time  0.22 forward time  0.03 nan share  0.00 ignore share (for classification tasks) 0.0065\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_function(config_sample, 1, add_name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
